apiVersion: config.openshift.io/v1
kind: ClusterOperator
metadata:
  annotations:
    exclude.release.openshift.io/internal-openshift-hosted: "true"
    include.release.openshift.io/self-managed-high-availability: "true"
    include.release.openshift.io/single-node-developer: "true"
  creationTimestamp: "2023-03-09T14:14:35Z"
  generation: 1
  managedFields:
  - apiVersion: config.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:exclude.release.openshift.io/internal-openshift-hosted: {}
          f:include.release.openshift.io/self-managed-high-availability: {}
          f:include.release.openshift.io/single-node-developer: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"b7590f0c-c37f-44e0-80d3-7b5df1e0e187"}: {}
      f:spec: {}
    manager: cluster-version-operator
    operation: Update
    time: "2023-03-09T14:14:35Z"
  - apiVersion: config.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        .: {}
        f:extension: {}
    manager: cluster-version-operator
    operation: Update
    subresource: status
    time: "2023-03-09T14:14:35Z"
  - apiVersion: config.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        f:conditions: {}
        f:relatedObjects: {}
        f:versions: {}
    manager: cluster-kube-scheduler-operator
    operation: Update
    subresource: status
    time: "2023-03-09T14:22:12Z"
  name: kube-scheduler
  ownerReferences:
  - apiVersion: config.openshift.io/v1
    controller: true
    kind: ClusterVersion
    name: version
    uid: b7590f0c-c37f-44e0-80d3-7b5df1e0e187
  resourceVersion: "4506"
  uid: 441925ee-aa23-4d3c-937b-d1809e7a63de
spec: {}
status:
  conditions:
  - lastTransitionTime: "2023-03-09T14:22:00Z"
    message: |-
      InstallerControllerDegraded: missing required resources: [secrets: kube-scheduler-client-cert-key, configmaps: config-1,kube-scheduler-cert-syncer-kubeconfig-1,kube-scheduler-pod-1,scheduler-kubeconfig-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1]
      NodeControllerDegraded: All master nodes are ready
      RevisionControllerDegraded: configmaps "kube-scheduler-pod" not found
      TargetConfigControllerDegraded: "serviceaccount/localhost-recovery-client": serviceaccounts "localhost-recovery-client" not found
    reason: AsExpected
    status: "False"
    type: Degraded
  - lastTransitionTime: "2023-03-09T14:22:09Z"
    message: 'NodeInstallerProgressing: 1 nodes are at revision 0; 0 nodes have achieved
      new revision 1'
    reason: NodeInstaller
    status: "True"
    type: Progressing
  - lastTransitionTime: "2023-03-09T14:22:00Z"
    message: 'StaticPodsAvailable: 0 nodes are active; 1 nodes are at revision 0;
      0 nodes have achieved new revision 1'
    reason: StaticPods_ZeroNodesActive
    status: "False"
    type: Available
  - lastTransitionTime: "2023-03-09T14:22:08Z"
    message: All is well
    reason: AsExpected
    status: "True"
    type: Upgradeable
  extension: null
  relatedObjects:
  - group: operator.openshift.io
    name: cluster
    resource: kubeschedulers
  - group: config.openshift.io
    name: ""
    resource: schedulers
  - group: ""
    name: openshift-config
    resource: namespaces
  - group: ""
    name: openshift-config-managed
    resource: namespaces
  - group: ""
    name: openshift-kube-scheduler
    resource: namespaces
  - group: ""
    name: openshift-kube-scheduler-operator
    resource: namespaces
  - group: controlplane.operator.openshift.io
    name: ""
    namespace: openshift-kube-apiserver
    resource: podnetworkconnectivitychecks
  versions:
  - name: raw-internal
    version: 4.13.0-0.ci.test-2023-03-09-115511-ci-ln-88xnydk-latest
