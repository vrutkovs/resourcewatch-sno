apiVersion: config.openshift.io/v1
kind: ClusterOperator
metadata:
  annotations:
    exclude.release.openshift.io/internal-openshift-hosted: "true"
    include.release.openshift.io/self-managed-high-availability: "true"
    include.release.openshift.io/single-node-developer: "true"
  creationTimestamp: "2023-03-08T12:00:44Z"
  generation: 1
  managedFields:
  - apiVersion: config.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:exclude.release.openshift.io/internal-openshift-hosted: {}
          f:include.release.openshift.io/self-managed-high-availability: {}
          f:include.release.openshift.io/single-node-developer: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"df6fb9e8-7fcf-4dfa-9adc-ffb076bfb757"}: {}
      f:spec: {}
    manager: cluster-version-operator
    operation: Update
    time: "2023-03-08T12:00:44Z"
  - apiVersion: config.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        .: {}
        f:extension: {}
    manager: cluster-version-operator
    operation: Update
    subresource: status
    time: "2023-03-08T12:00:45Z"
  - apiVersion: config.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        f:conditions: {}
        f:relatedObjects: {}
        f:versions: {}
    manager: cluster-kube-controller-manager-operator
    operation: Update
    subresource: status
    time: "2023-03-08T12:22:41Z"
  name: kube-controller-manager
  ownerReferences:
  - apiVersion: config.openshift.io/v1
    controller: true
    kind: ClusterVersion
    name: version
    uid: df6fb9e8-7fcf-4dfa-9adc-ffb076bfb757
  resourceVersion: "14463"
  uid: ae28a46b-58e3-46e0-8654-d3f4cf5ab63c
spec: {}
status:
  conditions:
  - lastTransitionTime: "2023-03-08T12:22:34Z"
    message: "StaticPodsDegraded: pod/kube-controller-manager-vrutkovs-sno container
      \"cluster-policy-controller\" is terminated: Completed: \nStaticPodsDegraded:
      pod/kube-controller-manager-vrutkovs-sno container \"kube-controller-manager\"
      is terminated: Completed: \nStaticPodsDegraded: pod/kube-controller-manager-vrutkovs-sno
      container \"kube-controller-manager-cert-syncer\" is terminated: Error: I0308
      12:22:09.823084       1 base_controller.go:67] Waiting for caches to sync for
      CertSyncController\nStaticPodsDegraded: I0308 12:22:09.823165       1 event.go:285]
      Event(v1.ObjectReference{Kind:\"Pod\", Namespace:\"openshift-kube-controller-manager\",
      Name:\"kube-controller-manager-vrutkovs-sno\", UID:\"\", APIVersion:\"v1\",
      ResourceVersion:\"\", FieldPath:\"\"}): type: 'Warning' reason: 'FastControllerResync'
      Controller \"CertSyncController\" resync interval is set to 0s which might lead
      to client request throttling\nStaticPodsDegraded: I0308 12:22:09.823384       1
      observer_polling.go:159] Starting file observer\nStaticPodsDegraded: I0308 12:22:09.924331
      \      1 base_controller.go:73] Caches are synced for CertSyncController \nStaticPodsDegraded:
      I0308 12:22:09.924366       1 base_controller.go:110] Starting #1 worker of
      CertSyncController controller ...\nStaticPodsDegraded: I0308 12:22:09.924427
      \      1 certsync_controller.go:66] Syncing configmaps: [{aggregator-client-ca
      false} {client-ca false} {trusted-ca-bundle true}]\nStaticPodsDegraded: I0308
      12:22:09.925001       1 certsync_controller.go:170] Syncing secrets: [{kube-controller-manager-client-cert-key
      false} {csr-signer false}]\nStaticPodsDegraded: I0308 12:22:10.370368       1
      certsync_controller.go:66] Syncing configmaps: [{aggregator-client-ca false}
      {client-ca false} {trusted-ca-bundle true}]\nStaticPodsDegraded: I0308 12:22:10.370724
      \      1 certsync_controller.go:170] Syncing secrets: [{kube-controller-manager-client-cert-key
      false} {csr-signer false}]\nStaticPodsDegraded: I0308 12:22:35.872791       1
      certsync_controller.go:66] Syncing configmaps: [{aggregator-client-ca false}
      {client-ca false} {trusted-ca-bundle true}]\nStaticPodsDegraded: I0308 12:22:35.873062
      \      1 certsync_controller.go:170] Syncing secrets: [{kube-controller-manager-client-cert-key
      false} {csr-signer false}]\nStaticPodsDegraded: \nStaticPodsDegraded: pod/kube-controller-manager-vrutkovs-sno
      container \"kube-controller-manager-recovery-controller\" is terminated: Completed:
      \nNodeControllerDegraded: All master nodes are ready"
    reason: AsExpected
    status: "False"
    type: Degraded
  - lastTransitionTime: "2023-03-08T12:18:16Z"
    message: 'NodeInstallerProgressing: 1 nodes are at revision 4; 0 nodes have achieved
      new revision 9'
    reason: NodeInstaller
    status: "True"
    type: Progressing
  - lastTransitionTime: "2023-03-08T12:15:38Z"
    message: 'StaticPodsAvailable: 1 nodes are active; 1 nodes are at revision 4;
      0 nodes have achieved new revision 9'
    reason: AsExpected
    status: "True"
    type: Available
  - lastTransitionTime: "2023-03-08T12:08:35Z"
    message: All is well
    reason: AsExpected
    status: "True"
    type: Upgradeable
  extension: null
  relatedObjects:
  - group: operator.openshift.io
    name: cluster
    resource: kubecontrollermanagers
  - group: ""
    name: openshift-config
    resource: namespaces
  - group: ""
    name: openshift-config-managed
    resource: namespaces
  - group: ""
    name: openshift-kube-controller-manager
    resource: namespaces
  - group: ""
    name: openshift-kube-controller-manager-operator
    resource: namespaces
  - group: ""
    name: kube-system
    resource: namespaces
  - group: certificates.k8s.io
    name: ""
    resource: certificatesigningrequests
  - group: ""
    name: ""
    resource: nodes
  - group: config.openshift.io
    name: cluster
    resource: nodes
  versions:
  - name: raw-internal
    version: 4.13.0-ec.4
  - name: operator
    version: 4.13.0-ec.4
  - name: kube-controller-manager
    version: 1.26.0
