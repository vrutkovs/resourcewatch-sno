apiVersion: config.openshift.io/v1
kind: ClusterOperator
metadata:
  annotations:
    exclude.release.openshift.io/internal-openshift-hosted: "true"
    include.release.openshift.io/self-managed-high-availability: "true"
    include.release.openshift.io/single-node-developer: "true"
  creationTimestamp: "2023-03-09T14:14:35Z"
  generation: 1
  managedFields:
  - apiVersion: config.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:exclude.release.openshift.io/internal-openshift-hosted: {}
          f:include.release.openshift.io/self-managed-high-availability: {}
          f:include.release.openshift.io/single-node-developer: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"b7590f0c-c37f-44e0-80d3-7b5df1e0e187"}: {}
      f:spec: {}
    manager: cluster-version-operator
    operation: Update
    time: "2023-03-09T14:14:35Z"
  - apiVersion: config.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        .: {}
        f:extension: {}
    manager: cluster-version-operator
    operation: Update
    subresource: status
    time: "2023-03-09T14:14:35Z"
  - apiVersion: config.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        f:conditions: {}
        f:relatedObjects: {}
        f:versions: {}
    manager: cluster-kube-controller-manager-operator
    operation: Update
    subresource: status
    time: "2023-03-09T14:32:01Z"
  name: kube-controller-manager
  ownerReferences:
  - apiVersion: config.openshift.io/v1
    controller: true
    kind: ClusterVersion
    name: version
    uid: b7590f0c-c37f-44e0-80d3-7b5df1e0e187
  resourceVersion: "13507"
  uid: fc4da80c-8238-45f0-831b-b76abd6e6070
spec: {}
status:
  conditions:
  - lastTransitionTime: "2023-03-09T14:24:40Z"
    message: |-
      GarbageCollectorDegraded: error fetching rules: Get "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/rules": dial tcp 172.30.121.173:9091: connect: connection refused
      NodeControllerDegraded: The master nodes not ready: node "vrutkovs-sno" not ready since 2023-03-09 14:32:01 +0000 UTC because KubeletNotReady (container runtime status check may not have completed yet)
    reason: GarbageCollector_Error::NodeController_MasterNodesReady
    status: "True"
    type: Degraded
  - lastTransitionTime: "2023-03-09T14:32:01Z"
    message: 'NodeInstallerProgressing: 1 nodes are at revision 5'
    reason: AsExpected
    status: "False"
    type: Progressing
  - lastTransitionTime: "2023-03-09T14:30:38Z"
    message: 'StaticPodsAvailable: 1 nodes are active; 1 nodes are at revision 5'
    reason: AsExpected
    status: "True"
    type: Available
  - lastTransitionTime: "2023-03-09T14:22:00Z"
    message: All is well
    reason: AsExpected
    status: "True"
    type: Upgradeable
  extension: null
  relatedObjects:
  - group: operator.openshift.io
    name: cluster
    resource: kubecontrollermanagers
  - group: ""
    name: openshift-config
    resource: namespaces
  - group: ""
    name: openshift-config-managed
    resource: namespaces
  - group: ""
    name: openshift-kube-controller-manager
    resource: namespaces
  - group: ""
    name: openshift-kube-controller-manager-operator
    resource: namespaces
  - group: ""
    name: kube-system
    resource: namespaces
  - group: certificates.k8s.io
    name: ""
    resource: certificatesigningrequests
  - group: ""
    name: ""
    resource: nodes
  - group: config.openshift.io
    name: cluster
    resource: nodes
  versions:
  - name: raw-internal
    version: 4.13.0-0.ci.test-2023-03-09-115511-ci-ln-88xnydk-latest
  - name: operator
    version: 4.13.0-0.ci.test-2023-03-09-115511-ci-ln-88xnydk-latest
  - name: kube-controller-manager
    version: 1.26.2
