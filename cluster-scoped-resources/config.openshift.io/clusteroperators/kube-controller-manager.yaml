apiVersion: config.openshift.io/v1
kind: ClusterOperator
metadata:
  annotations:
    exclude.release.openshift.io/internal-openshift-hosted: "true"
    include.release.openshift.io/self-managed-high-availability: "true"
    include.release.openshift.io/single-node-developer: "true"
  creationTimestamp: "2023-03-08T12:00:44Z"
  generation: 1
  managedFields:
  - apiVersion: config.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:exclude.release.openshift.io/internal-openshift-hosted: {}
          f:include.release.openshift.io/self-managed-high-availability: {}
          f:include.release.openshift.io/single-node-developer: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"df6fb9e8-7fcf-4dfa-9adc-ffb076bfb757"}: {}
      f:spec: {}
    manager: cluster-version-operator
    operation: Update
    time: "2023-03-08T12:00:44Z"
  - apiVersion: config.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        .: {}
        f:extension: {}
    manager: cluster-version-operator
    operation: Update
    subresource: status
    time: "2023-03-08T12:00:45Z"
  - apiVersion: config.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        f:conditions: {}
        f:relatedObjects: {}
        f:versions: {}
    manager: cluster-kube-controller-manager-operator
    operation: Update
    subresource: status
    time: "2023-03-08T12:16:58Z"
  name: kube-controller-manager
  ownerReferences:
  - apiVersion: config.openshift.io/v1
    controller: true
    kind: ClusterVersion
    name: version
    uid: df6fb9e8-7fcf-4dfa-9adc-ffb076bfb757
  resourceVersion: "7711"
  uid: ae28a46b-58e3-46e0-8654-d3f4cf5ab63c
spec: {}
status:
  conditions:
  - lastTransitionTime: "2023-03-08T12:11:40Z"
    message: "GarbageCollectorDegraded: error fetching rules: Get \"https://thanos-querier.openshift-monitoring.svc:9091/api/v1/rules\":
      dial tcp: lookup thanos-querier.openshift-monitoring.svc: i/o timeout\nKubeControllerManagerStaticResourcesDegraded:
      \"assets/kube-controller-manager/ns.yaml\" (string): Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager\":
      dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded:
      \"assets/kube-controller-manager/leader-election-rolebinding.yaml\" (string):
      Get \"https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager\":
      dial tcp 172.30.0.1:443: connect: connection refused\nKubeControllerManagerStaticResourcesDegraded:
      \"assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml\"
      (string): roles.rbac.authorization.k8s.io \"system:openshift:leader-election-lock-cluster-policy-controller\"
      is forbidden: User \"system:serviceaccount:openshift-kube-controller-manager-operator:kube-controller-manager-operator\"
      cannot get resource \"roles\" in API group \"rbac.authorization.k8s.io\" in
      the namespace \"openshift-kube-controller-manager\"\nKubeControllerManagerStaticResourcesDegraded:
      \"assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml\"
      (string): rolebindings.rbac.authorization.k8s.io \"system:openshift:leader-election-lock-cluster-policy-controller\"
      is forbidden: User \"system:serviceaccount:openshift-kube-controller-manager-operator:kube-controller-manager-operator\"
      cannot get resource \"rolebindings\" in API group \"rbac.authorization.k8s.io\"
      in the namespace \"openshift-kube-controller-manager\"\nKubeControllerManagerStaticResourcesDegraded:
      \nStaticPodsDegraded: pod/kube-controller-manager-vrutkovs-sno container \"cluster-policy-controller\"
      is terminated: Completed: \nStaticPodsDegraded: pod/kube-controller-manager-vrutkovs-sno
      container \"kube-controller-manager\" is terminated: Error: 0308 12:15:30.791362
      \      1 controllermanager.go:674] Started \"ttl-after-finished\"\nStaticPodsDegraded:
      I0308 12:15:30.791405       1 controllermanager.go:645] Starting \"persistentvolume-expander\"\nStaticPodsDegraded:
      I0308 12:15:30.791386       1 ttlafterfinished_controller.go:104] Starting TTL
      after finished controller\nStaticPodsDegraded: I0308 12:15:30.791453       1
      shared_informer.go:273] Waiting for caches to sync for TTL after finished\nStaticPodsDegraded:
      I0308 12:15:30.792854       1 plugins.go:646] \"Loaded volume plugin\" pluginName=\"kubernetes.io/azure-disk\"\nStaticPodsDegraded:
      I0308 12:15:30.792869       1 plugins.go:646] \"Loaded volume plugin\" pluginName=\"kubernetes.io/vsphere-volume\"\nStaticPodsDegraded:
      I0308 12:15:30.792884       1 plugins.go:646] \"Loaded volume plugin\" pluginName=\"kubernetes.io/portworx-volume\"\nStaticPodsDegraded:
      I0308 12:15:30.792891       1 plugins.go:646] \"Loaded volume plugin\" pluginName=\"kubernetes.io/rbd\"\nStaticPodsDegraded:
      I0308 12:15:30.792898       1 plugins.go:646] \"Loaded volume plugin\" pluginName=\"kubernetes.io/aws-ebs\"\nStaticPodsDegraded:
      I0308 12:15:30.792905       1 plugins.go:646] \"Loaded volume plugin\" pluginName=\"kubernetes.io/gce-pd\"\nStaticPodsDegraded:
      I0308 12:15:30.792912       1 plugins.go:646] \"Loaded volume plugin\" pluginName=\"kubernetes.io/azure-file\"\nStaticPodsDegraded:
      I0308 12:15:30.792919       1 plugins.go:646] \"Loaded volume plugin\" pluginName=\"kubernetes.io/fc\"\nStaticPodsDegraded:
      I0308 12:15:30.793026       1 controllermanager.go:674] Started \"persistentvolume-expander\"\nStaticPodsDegraded:
      I0308 12:15:30.793038       1 controllermanager.go:645] Starting \"namespace\"\nStaticPodsDegraded:
      I0308 12:15:30.793048       1 expand_controller.go:340] Starting expand controller\nStaticPodsDegraded:
      I0308 12:15:30.793058       1 shared_informer.go:273] Waiting for caches to
      sync for expand\nStaticPodsDegraded: I0308 12:15:30.874185       1 shared_informer.go:280]
      Caches are synced for tokens\nStaticPodsDegraded: E0308 12:16:20.829572       1
      namespaced_resources_deleter.go:162] unable to get all supported resources from
      server: the server has received too many requests and has asked us to try again
      later\nStaticPodsDegraded: F0308 12:16:20.829587       1 namespaced_resources_deleter.go:165]
      Unable to get any supported resources from server: the server has received too
      many requests and has asked us to try again later\nStaticPodsDegraded: \nStaticPodsDegraded:
      pod/kube-controller-manager-vrutkovs-sno container \"kube-controller-manager-cert-syncer\"
      is terminated: Error: troller-manager/configmaps?limit=500&resourceVersion=0\":
      x509: certificate signed by unknown authority\nStaticPodsDegraded: E0308 12:16:13.460253
      \      1 reflector.go:140] k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169:
      Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?limit=500&resourceVersion=0\":
      x509: certificate signed by unknown authority\nStaticPodsDegraded: E0308 12:16:14.742498
      \      1 event.go:276] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:\"\",
      APIVersion:\"\"}, ObjectMeta:v1.ObjectMeta{Name:\"kube-controller-manager-vrutkovs-sno.174a70b0200f07b7\",
      GenerateName:\"\", Namespace:\"openshift-kube-controller-manager\", SelfLink:\"\",
      UID:\"\", ResourceVersion:\"\", Generation:0, CreationTimestamp:time.Date(1,
      time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil),
      Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil),
      Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:\"Pod\",
      Namespace:\"openshift-kube-controller-manager\", Name:\"kube-controller-manager-vrutkovs-sno\",
      UID:\"\", APIVersion:\"v1\", ResourceVersion:\"\", FieldPath:\"\"}, Reason:\"FastControllerResync\",
      Message:\"Controller \\\"CertSyncController\\\" resync interval is set to 0s
      which might lead to client request throttling\", Source:v1.EventSource{Component:\"cert-syncer-certsynccontroller\",
      Host:\"\"}, FirstTimestamp:time.Date(2023, time.March, 8, 12, 15, 12, 903342007,
      time.Local), LastTimestamp:time.Date(2023, time.March, 8, 12, 15, 12, 903342007,
      time.Local), Count:1, Type:\"Warning\", EventTime:time.Date(1, time.January,
      1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:\"\", Related:(*v1.ObjectReference)(nil),
      ReportingController:\"\", ReportingInstance:\"\"}': 'Post \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/events\":
      x509: certificate signed by unknown authority'(may retry after sleeping)\nStaticPodsDegraded:
      pod/kube-controller-manager-vrutkovs-sno container \"kube-controller-manager-recovery-controller\"
      is terminated: Completed: "
    reason: GarbageCollector_Error::KubeControllerManagerStaticResources_SyncError::StaticPods_Error
    status: "True"
    type: Degraded
  - lastTransitionTime: "2023-03-08T12:15:45Z"
    message: 'NodeInstallerProgressing: 1 nodes are at revision 3; 0 nodes have achieved
      new revision 4'
    reason: NodeInstaller
    status: "True"
    type: Progressing
  - lastTransitionTime: "2023-03-08T12:15:38Z"
    message: 'StaticPodsAvailable: 1 nodes are active; 1 nodes are at revision 3;
      0 nodes have achieved new revision 4'
    reason: AsExpected
    status: "True"
    type: Available
  - lastTransitionTime: "2023-03-08T12:08:35Z"
    message: All is well
    reason: AsExpected
    status: "True"
    type: Upgradeable
  extension: null
  relatedObjects:
  - group: operator.openshift.io
    name: cluster
    resource: kubecontrollermanagers
  - group: ""
    name: openshift-config
    resource: namespaces
  - group: ""
    name: openshift-config-managed
    resource: namespaces
  - group: ""
    name: openshift-kube-controller-manager
    resource: namespaces
  - group: ""
    name: openshift-kube-controller-manager-operator
    resource: namespaces
  - group: ""
    name: kube-system
    resource: namespaces
  - group: certificates.k8s.io
    name: ""
    resource: certificatesigningrequests
  - group: ""
    name: ""
    resource: nodes
  - group: config.openshift.io
    name: cluster
    resource: nodes
  versions:
  - name: raw-internal
    version: 4.13.0-ec.4
  - name: operator
    version: 4.13.0-ec.4
  - name: kube-controller-manager
    version: 1.26.0
