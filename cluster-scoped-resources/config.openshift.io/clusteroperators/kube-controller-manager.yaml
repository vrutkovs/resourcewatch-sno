apiVersion: config.openshift.io/v1
kind: ClusterOperator
metadata:
  annotations:
    exclude.release.openshift.io/internal-openshift-hosted: "true"
    include.release.openshift.io/self-managed-high-availability: "true"
    include.release.openshift.io/single-node-developer: "true"
  creationTimestamp: "2023-03-09T14:14:35Z"
  generation: 1
  managedFields:
  - apiVersion: config.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:exclude.release.openshift.io/internal-openshift-hosted: {}
          f:include.release.openshift.io/self-managed-high-availability: {}
          f:include.release.openshift.io/single-node-developer: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"b7590f0c-c37f-44e0-80d3-7b5df1e0e187"}: {}
      f:spec: {}
    manager: cluster-version-operator
    operation: Update
    time: "2023-03-09T14:14:35Z"
  - apiVersion: config.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        .: {}
        f:extension: {}
    manager: cluster-version-operator
    operation: Update
    subresource: status
    time: "2023-03-09T14:14:35Z"
  - apiVersion: config.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        f:conditions: {}
        f:relatedObjects: {}
        f:versions: {}
    manager: cluster-kube-controller-manager-operator
    operation: Update
    subresource: status
    time: "2023-03-09T14:22:39Z"
  name: kube-controller-manager
  ownerReferences:
  - apiVersion: config.openshift.io/v1
    controller: true
    kind: ClusterVersion
    name: version
    uid: b7590f0c-c37f-44e0-80d3-7b5df1e0e187
  resourceVersion: "5758"
  uid: fc4da80c-8238-45f0-831b-b76abd6e6070
spec: {}
status:
  conditions:
  - lastTransitionTime: "2023-03-09T14:22:00Z"
    message: |-
      InstallerControllerDegraded: missing required resources: [configmaps: aggregator-client-ca,client-ca, secrets: kube-controller-manager-client-cert-key, configmaps: cluster-policy-controller-config-1,config-1,controller-manager-kubeconfig-1,kube-controller-cert-syncer-kubeconfig-1,kube-controller-manager-pod-1,recycler-config-1,service-ca-1,serviceaccount-ca-1, secrets: localhost-recovery-client-token-1,service-account-private-key-1]
      GarbageCollectorDegraded: error fetching rules: Get "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/rules": dial tcp 172.30.121.173:9091: connect: connection refused
      NodeControllerDegraded: All master nodes are ready
      RevisionControllerDegraded: configmaps "kube-controller-manager-pod" not found
    reason: AsExpected
    status: "False"
    type: Degraded
  - lastTransitionTime: "2023-03-09T14:22:11Z"
    message: 'NodeInstallerProgressing: 1 nodes are at revision 0; 0 nodes have achieved
      new revision 1'
    reason: NodeInstaller
    status: "True"
    type: Progressing
  - lastTransitionTime: "2023-03-09T14:22:00Z"
    message: 'StaticPodsAvailable: 0 nodes are active; 1 nodes are at revision 0;
      0 nodes have achieved new revision 1'
    reason: StaticPods_ZeroNodesActive
    status: "False"
    type: Available
  - lastTransitionTime: "2023-03-09T14:22:00Z"
    message: All is well
    reason: AsExpected
    status: "True"
    type: Upgradeable
  extension: null
  relatedObjects:
  - group: operator.openshift.io
    name: cluster
    resource: kubecontrollermanagers
  - group: ""
    name: openshift-config
    resource: namespaces
  - group: ""
    name: openshift-config-managed
    resource: namespaces
  - group: ""
    name: openshift-kube-controller-manager
    resource: namespaces
  - group: ""
    name: openshift-kube-controller-manager-operator
    resource: namespaces
  - group: ""
    name: kube-system
    resource: namespaces
  - group: certificates.k8s.io
    name: ""
    resource: certificatesigningrequests
  - group: ""
    name: ""
    resource: nodes
  - group: config.openshift.io
    name: cluster
    resource: nodes
  versions:
  - name: raw-internal
    version: 4.13.0-0.ci.test-2023-03-09-115511-ci-ln-88xnydk-latest
