apiVersion: operator.openshift.io/v1
kind: KubeScheduler
metadata:
  annotations:
    include.release.openshift.io/ibm-cloud-managed: "true"
    include.release.openshift.io/self-managed-high-availability: "true"
    include.release.openshift.io/single-node-developer: "true"
    release.openshift.io/create-only: "true"
  creationTimestamp: "2023-03-09T14:14:46Z"
  generation: 1
  managedFields:
  - apiVersion: operator.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:include.release.openshift.io/ibm-cloud-managed: {}
          f:include.release.openshift.io/self-managed-high-availability: {}
          f:include.release.openshift.io/single-node-developer: {}
          f:release.openshift.io/create-only: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"b7590f0c-c37f-44e0-80d3-7b5df1e0e187"}: {}
      f:spec:
        .: {}
        f:logLevel: {}
        f:managementState: {}
        f:operatorLogLevel: {}
    manager: cluster-version-operator
    operation: Update
    time: "2023-03-09T14:14:46Z"
  - apiVersion: operator.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        .: {}
        f:conditions: {}
        f:latestAvailableRevision: {}
        f:latestAvailableRevisionReason: {}
        f:nodeStatuses: {}
        f:readyReplicas: {}
    manager: cluster-kube-scheduler-operator
    operation: Update
    subresource: status
    time: "2023-03-09T14:22:01Z"
  name: cluster
  ownerReferences:
  - apiVersion: config.openshift.io/v1
    kind: ClusterVersion
    name: version
    uid: b7590f0c-c37f-44e0-80d3-7b5df1e0e187
  resourceVersion: "3721"
  uid: 48eb058e-3e1d-45d9-baa8-cf6a53778010
spec:
  logLevel: Normal
  managementState: Managed
  operatorLogLevel: Normal
status:
  conditions:
  - lastTransitionTime: "2023-03-09T14:22:00Z"
    message: 'missing required resources: [secrets: kube-scheduler-client-cert-key,
      configmaps: config-0,kube-scheduler-cert-syncer-kubeconfig-0,kube-scheduler-pod-0,scheduler-kubeconfig-0,serviceaccount-ca-0,
      secrets: localhost-recovery-client-token-0]'
    reason: Error
    status: "True"
    type: InstallerControllerDegraded
  - lastTransitionTime: "2023-03-09T14:22:00Z"
    message: 0 nodes are active; 1 nodes are at revision 0
    reason: ZeroNodesActive
    status: "False"
    type: StaticPodsAvailable
  - lastTransitionTime: "2023-03-09T14:22:00Z"
    message: 1 nodes are at revision 0
    reason: AllNodesAtLatestRevision
    status: "False"
    type: NodeInstallerProgressing
  - lastTransitionTime: "2023-03-09T14:22:00Z"
    status: "False"
    type: NodeInstallerDegraded
  - lastTransitionTime: "2023-03-09T14:22:00Z"
    message: All master nodes are ready
    reason: MasterNodesReady
    status: "False"
    type: NodeControllerDegraded
  - lastTransitionTime: "2023-03-09T14:22:00Z"
    reason: AsExpected
    status: "False"
    type: MissingStaticPodControllerDegraded
  latestAvailableRevision: 0
  latestAvailableRevisionReason: ""
  nodeStatuses:
  - currentRevision: 0
    nodeName: vrutkovs-sno
  readyReplicas: 0
