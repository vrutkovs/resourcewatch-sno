apiVersion: operator.openshift.io/v1
kind: KubeControllerManager
metadata:
  annotations:
    include.release.openshift.io/ibm-cloud-managed: "true"
    include.release.openshift.io/self-managed-high-availability: "true"
    include.release.openshift.io/single-node-developer: "true"
    release.openshift.io/create-only: "true"
  creationTimestamp: "2023-03-09T14:14:46Z"
  generation: 3
  managedFields:
  - apiVersion: operator.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:include.release.openshift.io/ibm-cloud-managed: {}
          f:include.release.openshift.io/self-managed-high-availability: {}
          f:include.release.openshift.io/single-node-developer: {}
          f:release.openshift.io/create-only: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"b7590f0c-c37f-44e0-80d3-7b5df1e0e187"}: {}
      f:spec:
        .: {}
        f:logLevel: {}
        f:managementState: {}
        f:operatorLogLevel: {}
        f:useMoreSecureServiceCA: {}
    manager: cluster-version-operator
    operation: Update
    time: "2023-03-09T14:14:46Z"
  - apiVersion: operator.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:spec:
        f:observedConfig:
          .: {}
          f:extendedArguments:
            .: {}
            f:cluster-cidr: {}
            f:cluster-name: {}
            f:feature-gates: {}
            f:service-cluster-ip-range: {}
          f:featureGates: {}
          f:serviceServingCert:
            .: {}
            f:certFile: {}
          f:servingInfo:
            .: {}
            f:cipherSuites: {}
            f:minTLSVersion: {}
        f:unsupportedConfigOverrides: {}
    manager: cluster-kube-controller-manager-operator
    operation: Update
    time: "2023-03-09T14:22:14Z"
  - apiVersion: operator.openshift.io/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        .: {}
        f:conditions: {}
        f:latestAvailableRevision: {}
        f:latestAvailableRevisionReason: {}
        f:nodeStatuses: {}
        f:readyReplicas: {}
    manager: cluster-kube-controller-manager-operator
    operation: Update
    subresource: status
    time: "2023-03-09T14:33:47Z"
  name: cluster
  ownerReferences:
  - apiVersion: config.openshift.io/v1
    kind: ClusterVersion
    name: version
    uid: b7590f0c-c37f-44e0-80d3-7b5df1e0e187
  resourceVersion: "16573"
  uid: b5866809-2025-4ddf-b687-3992e2169b2b
spec:
  logLevel: Normal
  managementState: Managed
  observedConfig:
    extendedArguments:
      cluster-cidr:
      - 10.128.0.0/14
      cluster-name:
      - ocp-rd9g5
      feature-gates:
      - APIPriorityAndFairness=true
      - RotateKubeletServerCertificate=true
      - DownwardAPIHugePages=true
      - OpenShiftPodSecurityAdmission=true
      - RetroactiveDefaultStorageClass=false
      service-cluster-ip-range:
      - 172.30.0.0/16
    featureGates:
    - APIPriorityAndFairness=true
    - RotateKubeletServerCertificate=true
    - DownwardAPIHugePages=true
    - OpenShiftPodSecurityAdmission=true
    - RetroactiveDefaultStorageClass=false
    serviceServingCert:
      certFile: /etc/kubernetes/static-pod-resources/configmaps/service-ca/ca-bundle.crt
    servingInfo:
      cipherSuites:
      - TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256
      - TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
      - TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384
      - TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
      - TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256
      - TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      minTLSVersion: VersionTLS12
  operatorLogLevel: Normal
  unsupportedConfigOverrides: null
  useMoreSecureServiceCA: true
status:
  conditions:
  - lastTransitionTime: "2023-03-09T14:22:00Z"
    reason: NoUnsupportedConfigOverrides
    status: "True"
    type: UnsupportedConfigOverridesUpgradeable
  - lastTransitionTime: "2023-03-09T14:29:39Z"
    status: "False"
    type: InstallerControllerDegraded
  - lastTransitionTime: "2023-03-09T14:30:38Z"
    message: 1 nodes are active; 1 nodes are at revision 5
    status: "True"
    type: StaticPodsAvailable
  - lastTransitionTime: "2023-03-09T14:31:55Z"
    message: 1 nodes are at revision 5
    reason: AllNodesAtLatestRevision
    status: "False"
    type: NodeInstallerProgressing
  - lastTransitionTime: "2023-03-09T14:22:00Z"
    status: "False"
    type: NodeInstallerDegraded
  - lastTransitionTime: "2023-03-09T14:22:00Z"
    reason: ProfileEmpty
    status: "False"
    type: WorkerLatencyProfileProgressing
  - lastTransitionTime: "2023-03-09T14:22:00Z"
    message: latency profile not set on cluster
    reason: ProfileEmpty
    status: "True"
    type: WorkerLatencyProfileComplete
  - lastTransitionTime: "2023-03-09T14:22:00Z"
    reason: AsExpected
    status: "False"
    type: WorkerLatencyProfileDegraded
  - lastTransitionTime: "2023-03-09T14:22:00Z"
    reason: AsExpected
    status: "False"
    type: MissingStaticPodControllerDegraded
  - lastTransitionTime: "2023-03-09T14:31:41Z"
    status: "False"
    type: StaticPodsDegraded
  - lastTransitionTime: "2023-03-09T14:33:47Z"
    reason: AsExpected
    status: "False"
    type: GarbageCollectorDegraded
  - lastTransitionTime: "2023-03-09T14:32:02Z"
    message: All master nodes are ready
    reason: MasterNodesReady
    status: "False"
    type: NodeControllerDegraded
  - lastTransitionTime: "2023-03-09T14:29:38Z"
    status: "False"
    type: RevisionControllerDegraded
  - lastTransitionTime: "2023-03-09T14:22:04Z"
    status: "False"
    type: CertRotation_CSRSigningCert_Degraded
  - lastTransitionTime: "2023-03-09T14:22:05Z"
    status: "False"
    type: ResourceSyncControllerDegraded
  - lastTransitionTime: "2023-03-09T14:22:08Z"
    reason: AsExpected
    status: "False"
    type: GuardControllerDegraded
  - lastTransitionTime: "2023-03-09T14:22:21Z"
    status: "False"
    type: ConfigObservationDegraded
  - lastTransitionTime: "2023-03-09T14:22:12Z"
    reason: AsExpected
    status: "False"
    type: BackingResourceControllerDegraded
  - lastTransitionTime: "2023-03-09T14:32:06Z"
    status: "False"
    type: SATokenSignerDegraded
  - lastTransitionTime: "2023-03-09T14:22:18Z"
    status: "False"
    type: InstallerPodPendingDegraded
  - lastTransitionTime: "2023-03-09T14:22:18Z"
    status: "False"
    type: InstallerPodContainerWaitingDegraded
  - lastTransitionTime: "2023-03-09T14:22:18Z"
    status: "False"
    type: InstallerPodNetworkingDegraded
  - lastTransitionTime: "2023-03-09T14:33:37Z"
    message: |
      "assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused
      "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused
      "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused
      "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused
      "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused
      "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused
      "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): clusterroles.rbac.authorization.k8s.io "system:openshift:controller:podsecurity-admission-label-syncer-controller" is forbidden: User "system:serviceaccount:openshift-kube-controller-manager-operator:kube-controller-manager-operator" cannot get resource "clusterroles" in API group "rbac.authorization.k8s.io" at the cluster scope
      "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): clusterrolebindings.rbac.authorization.k8s.io "system:openshift:controller:podsecurity-admission-label-syncer-controller" is forbidden: User "system:serviceaccount:openshift-kube-controller-manager-operator:kube-controller-manager-operator" cannot get resource "clusterrolebindings" in API group "rbac.authorization.k8s.io" at the cluster scope
      "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): namespaces "openshift-infra" is forbidden: User "system:serviceaccount:openshift-kube-controller-manager-operator:kube-controller-manager-operator" cannot get resource "namespaces" in API group "" in the namespace "openshift-infra"
      "assets/kube-controller-manager/svc.yaml" (string): services "kube-controller-manager" is forbidden: User "system:serviceaccount:openshift-kube-controller-manager-operator:kube-controller-manager-operator" cannot get resource "services" in API group "" in the namespace "openshift-kube-controller-manager"
      "assets/kube-controller-manager/sa.yaml" (string): serviceaccounts "kube-controller-manager-sa" is forbidden: User "system:serviceaccount:openshift-kube-controller-manager-operator:kube-controller-manager-operator" cannot get resource "serviceaccounts" in API group "" in the namespace "openshift-kube-controller-manager"
      "assets/kube-controller-manager/recycler-sa.yaml" (string): serviceaccounts "pv-recycler-controller" is forbidden: User "system:serviceaccount:openshift-kube-controller-manager-operator:kube-controller-manager-operator" cannot get resource "serviceaccounts" in API group "" in the namespace "openshift-infra"
    reason: SyncError
    status: "True"
    type: KubeControllerManagerStaticResourcesDegraded
  - lastTransitionTime: "2023-03-09T14:22:33Z"
    status: "True"
    type: Upgradeable
  - lastTransitionTime: "2023-03-09T14:30:43Z"
    status: "False"
    type: CloudControllerOwner
  - lastTransitionTime: "2023-03-09T14:32:16Z"
    status: "False"
    type: TargetConfigControllerDegraded
  latestAvailableRevision: 5
  latestAvailableRevisionReason: ""
  nodeStatuses:
  - currentRevision: 5
    nodeName: vrutkovs-sno
  readyReplicas: 0
