apiVersion: v1
kind: Pod
metadata:
  annotations:
    networkoperator.openshift.io/cluster-network-cidr: 10.128.0.0/14
    networkoperator.openshift.io/ip-family-mode: single-stack
  creationTimestamp: "2023-03-09T14:20:33Z"
  generateName: ovnkube-master-
  labels:
    app: ovnkube-master
    component: network
    controller-revision-hash: 69548bc6ff
    kubernetes.io/os: linux
    openshift.io/component: network
    ovn-db-pod: "true"
    pod-template-generation: "1"
    type: infra
  managedFields:
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:networkoperator.openshift.io/cluster-network-cidr: {}
          f:networkoperator.openshift.io/ip-family-mode: {}
          f:target.workload.openshift.io/management: {}
        f:generateName: {}
        f:labels:
          .: {}
          f:app: {}
          f:component: {}
          f:controller-revision-hash: {}
          f:kubernetes.io/os: {}
          f:openshift.io/component: {}
          f:ovn-db-pod: {}
          f:pod-template-generation: {}
          f:type: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"5e54e35f-7fe1-4309-a412-ba71c74af3ed"}: {}
      f:spec:
        f:affinity:
          .: {}
          f:nodeAffinity:
            .: {}
            f:requiredDuringSchedulingIgnoredDuringExecution: {}
        f:containers:
          k:{"name":"kube-rbac-proxy"}:
            .: {}
            f:command: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:ports:
              .: {}
              k:{"containerPort":9102,"protocol":"TCP"}:
                .: {}
                f:containerPort: {}
                f:hostPort: {}
                f:name: {}
                f:protocol: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/etc/pki/tls/metrics-cert"}:
                .: {}
                f:mountPath: {}
                f:name: {}
                f:readOnly: {}
          k:{"name":"nbdb"}:
            .: {}
            f:command: {}
            f:env:
              .: {}
              k:{"name":"K8S_NODE_IP"}:
                .: {}
                f:name: {}
                f:valueFrom:
                  .: {}
                  f:fieldRef: {}
              k:{"name":"OVN_LOG_LEVEL"}:
                .: {}
                f:name: {}
                f:value: {}
              k:{"name":"OVN_NORTHD_PROBE_INTERVAL"}:
                .: {}
                f:name: {}
                f:value: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:lifecycle:
              .: {}
              f:postStart:
                .: {}
                f:exec:
                  .: {}
                  f:command: {}
              f:preStop:
                .: {}
                f:exec:
                  .: {}
                  f:command: {}
            f:name: {}
            f:ports:
              .: {}
              k:{"containerPort":9641,"protocol":"TCP"}:
                .: {}
                f:containerPort: {}
                f:hostPort: {}
                f:name: {}
                f:protocol: {}
              k:{"containerPort":9643,"protocol":"TCP"}:
                .: {}
                f:containerPort: {}
                f:hostPort: {}
                f:name: {}
                f:protocol: {}
            f:readinessProbe:
              .: {}
              f:exec:
                .: {}
                f:command: {}
              f:failureThreshold: {}
              f:periodSeconds: {}
              f:successThreshold: {}
              f:timeoutSeconds: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/env"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/openvswitch/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/ovn/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/ovn-ca"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/ovn-cert"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/run/openvswitch/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/run/ovn/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/var/lib/openvswitch/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
          k:{"name":"northd"}:
            .: {}
            f:command: {}
            f:env:
              .: {}
              k:{"name":"OVN_LOG_LEVEL"}:
                .: {}
                f:name: {}
                f:value: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:lifecycle:
              .: {}
              f:preStop:
                .: {}
                f:exec:
                  .: {}
                  f:command: {}
            f:name: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/env"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/openvswitch/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/ovn-ca"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/ovn-cert"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/run/openvswitch/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/run/ovn/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/var/lib/openvswitch/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
          k:{"name":"ovn-dbchecker"}:
            .: {}
            f:command: {}
            f:env:
              .: {}
              k:{"name":"K8S_NODE_IP"}:
                .: {}
                f:name: {}
                f:valueFrom:
                  .: {}
                  f:fieldRef: {}
              k:{"name":"OVN_KUBE_LOG_LEVEL"}:
                .: {}
                f:name: {}
                f:value: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/env"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/openvswitch/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/ovn/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/ovn-ca"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/ovn-cert"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/run/openvswitch/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/run/ovn/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/run/ovnkube-config/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/var/lib/openvswitch/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
          k:{"name":"ovnkube-master"}:
            .: {}
            f:command: {}
            f:env:
              .: {}
              k:{"name":"K8S_NODE"}:
                .: {}
                f:name: {}
                f:valueFrom:
                  .: {}
                  f:fieldRef: {}
              k:{"name":"OVN_KUBE_LOG_LEVEL"}:
                .: {}
                f:name: {}
                f:value: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:ports:
              .: {}
              k:{"containerPort":29102,"protocol":"TCP"}:
                .: {}
                f:containerPort: {}
                f:hostPort: {}
                f:name: {}
                f:protocol: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/env"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/openvswitch/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/ovn/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/systemd/system"}:
                .: {}
                f:mountPath: {}
                f:name: {}
                f:readOnly: {}
              k:{"mountPath":"/ovn-ca"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/ovn-cert"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/run/openvswitch/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/run/ovn/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/run/ovnkube-config/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/var/lib/openvswitch/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
          k:{"name":"sbdb"}:
            .: {}
            f:command: {}
            f:env:
              .: {}
              k:{"name":"K8S_NODE_IP"}:
                .: {}
                f:name: {}
                f:valueFrom:
                  .: {}
                  f:fieldRef: {}
              k:{"name":"OVN_LOG_LEVEL"}:
                .: {}
                f:name: {}
                f:value: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:lifecycle:
              .: {}
              f:postStart:
                .: {}
                f:exec:
                  .: {}
                  f:command: {}
              f:preStop:
                .: {}
                f:exec:
                  .: {}
                  f:command: {}
            f:name: {}
            f:ports:
              .: {}
              k:{"containerPort":9642,"protocol":"TCP"}:
                .: {}
                f:containerPort: {}
                f:hostPort: {}
                f:name: {}
                f:protocol: {}
              k:{"containerPort":9644,"protocol":"TCP"}:
                .: {}
                f:containerPort: {}
                f:hostPort: {}
                f:name: {}
                f:protocol: {}
            f:readinessProbe:
              .: {}
              f:exec:
                .: {}
                f:command: {}
              f:failureThreshold: {}
              f:periodSeconds: {}
              f:successThreshold: {}
              f:timeoutSeconds: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/env"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/openvswitch/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/ovn/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/ovn-ca"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/ovn-cert"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/run/openvswitch/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/run/ovn/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/var/lib/openvswitch/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
        f:dnsPolicy: {}
        f:enableServiceLinks: {}
        f:hostNetwork: {}
        f:nodeSelector: {}
        f:priorityClassName: {}
        f:restartPolicy: {}
        f:schedulerName: {}
        f:securityContext: {}
        f:serviceAccount: {}
        f:serviceAccountName: {}
        f:terminationGracePeriodSeconds: {}
        f:tolerations: {}
        f:volumes:
          .: {}
          k:{"name":"env-overrides"}:
            .: {}
            f:configMap:
              .: {}
              f:defaultMode: {}
              f:name: {}
              f:optional: {}
            f:name: {}
          k:{"name":"etc-openvswitch"}:
            .: {}
            f:hostPath:
              .: {}
              f:path: {}
              f:type: {}
            f:name: {}
          k:{"name":"ovn-ca"}:
            .: {}
            f:configMap:
              .: {}
              f:defaultMode: {}
              f:name: {}
            f:name: {}
          k:{"name":"ovn-cert"}:
            .: {}
            f:name: {}
            f:secret:
              .: {}
              f:defaultMode: {}
              f:secretName: {}
          k:{"name":"ovn-master-metrics-cert"}:
            .: {}
            f:name: {}
            f:secret:
              .: {}
              f:defaultMode: {}
              f:optional: {}
              f:secretName: {}
          k:{"name":"ovnkube-config"}:
            .: {}
            f:configMap:
              .: {}
              f:defaultMode: {}
              f:name: {}
            f:name: {}
          k:{"name":"run-openvswitch"}:
            .: {}
            f:hostPath:
              .: {}
              f:path: {}
              f:type: {}
            f:name: {}
          k:{"name":"run-ovn"}:
            .: {}
            f:hostPath:
              .: {}
              f:path: {}
              f:type: {}
            f:name: {}
          k:{"name":"systemd-units"}:
            .: {}
            f:hostPath:
              .: {}
              f:path: {}
              f:type: {}
            f:name: {}
          k:{"name":"var-lib-openvswitch"}:
            .: {}
            f:hostPath:
              .: {}
              f:path: {}
              f:type: {}
            f:name: {}
    manager: kube-controller-manager
    operation: Update
    time: "2023-03-09T14:20:33Z"
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        f:conditions:
          k:{"type":"ContainersReady"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Initialized"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Ready"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
        f:containerStatuses: {}
        f:hostIP: {}
        f:phase: {}
        f:podIP: {}
        f:podIPs:
          .: {}
          k:{"ip":"10.0.130.93"}:
            .: {}
            f:ip: {}
        f:startTime: {}
    manager: kubelet
    operation: Update
    subresource: status
    time: "2023-03-09T14:32:07Z"
  name: ovnkube-master-c82lr
  namespace: openshift-ovn-kubernetes
  ownerReferences:
  - apiVersion: apps/v1
    blockOwnerDeletion: true
    controller: true
    kind: DaemonSet
    name: ovnkube-master
    uid: 5e54e35f-7fe1-4309-a412-ba71c74af3ed
  resourceVersion: "14218"
  uid: 9e75d9d6-b616-493a-90a5-773d93d969d6
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchFields:
          - key: metadata.name
            operator: In
            values:
            - vrutkovs-sno
  containers:
  - command:
    - /bin/bash
    - -c
    - |
      set -xem
      if [[ -f /env/_master ]]; then
        set -o allexport
        source /env/_master
        set +o allexport
      fi

      quit() {
        echo "$(date -Iseconds) - stopping ovn-northd"
        OVN_MANAGE_OVSDB=no /usr/share/ovn/scripts/ovn-ctl stop_northd
        echo "$(date -Iseconds) - ovn-northd stopped"
        rm -f /var/run/ovn/ovn-northd.pid
        exit 0
      }
      # end of quit
      trap quit TERM INT

      echo "$(date -Iseconds) - starting ovn-northd"
      exec ovn-northd \
        --no-chdir "-vconsole:${OVN_LOG_LEVEL}" -vfile:off "-vPATTERN:console:%D{%Y-%m-%dT%H:%M:%S.###Z}|%05N|%c%T|%p|%m" \
        --ovnnb-db "ssl:10.0.130.93:9641" \
        --ovnsb-db "ssl:10.0.130.93:9642" \
        --pidfile /var/run/ovn/ovn-northd.pid \
        --n-threads=1 \
        -p /ovn-cert/tls.key \
        -c /ovn-cert/tls.crt \
        -C /ovn-ca/ca-bundle.crt &

      wait $!
    env:
    - name: OVN_LOG_LEVEL
      value: info
    image: registry.build05.ci.openshift.org/ci-ln-88xnydk/stable@sha256:d554d78ce21caa55b704d4621d7a2ba806dd6321912c36d5cd8b61e9a0934d0b
    imagePullPolicy: IfNotPresent
    lifecycle:
      preStop:
        exec:
          command:
          - /bin/bash
          - -c
          - OVN_MANAGE_OVSDB=no /usr/share/ovn/scripts/ovn-ctl stop_northd
    name: northd
    resources:
      requests:
        cpu: 10m
        memory: 300Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/openvswitch/
      name: etc-openvswitch
    - mountPath: /var/lib/openvswitch/
      name: var-lib-openvswitch
    - mountPath: /run/openvswitch/
      name: run-openvswitch
    - mountPath: /run/ovn/
      name: run-ovn
    - mountPath: /env
      name: env-overrides
    - mountPath: /ovn-cert
      name: ovn-cert
    - mountPath: /ovn-ca
      name: ovn-ca
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-vbjr8
      readOnly: true
  - command:
    - /bin/bash
    - -c
    - "set -xem\nif [[ -f /env/_master ]]; then\n  set -o allexport\n  source /env/_master\n
      \ set +o allexport\nfi\n\nquit() {\n  echo \"$(date -Iseconds) - stopping nbdb\"\n
      \ /usr/share/ovn/scripts/ovn-ctl stop_nb_ovsdb\n  echo \"$(date -Iseconds) -
      nbdb stopped\"\n  rm -f /var/run/ovn/ovnnb_db.pid\n  exit 0\n}\n# end of quit\ntrap
      quit TERM INT\n\nbracketify() { case \"$1\" in *:*) echo \"[$1]\" ;; *) echo
      \"$1\" ;; esac }\n# initialize variables\novn_kubernetes_namespace=openshift-ovn-kubernetes\novndb_ctl_ssl_opts=\"-p
      /ovn-cert/tls.key -c /ovn-cert/tls.crt -C /ovn-ca/ca-bundle.crt\"\ntransport=\"ssl\"\novn_raft_conn_ip_url_suffix=\"\"\nif
      [[ \"${K8S_NODE_IP}\" == *\":\"* ]]; then\n  ovn_raft_conn_ip_url_suffix=\":[::]\"\nfi\ndb=\"nb\"\ndb_port=\"9641\"\novn_db_file=\"/etc/ovn/ovn${db}_db.db\"\n#
      checks if a db pod is part of a current cluster\ndb_part_of_cluster() {\n  local
      pod=${1}\n  local db=${2}\n  local port=${3}\n  echo \"Checking if ${pod} is
      part of cluster\"\n  # TODO: change to use '--request-timeout=5s', if https://github.com/kubernetes/kubernetes/issues/49343
      is fixed. \n  init_ip=$(timeout 5 kubectl get pod -n ${ovn_kubernetes_namespace}
      ${pod} -o=jsonpath='{.status.podIP}')\n  if [[ $? != 0 ]]; then\n    echo \"Unable
      to get ${pod} ip \"\n    return 1\n  fi\n  echo \"Found ${pod} ip: $init_ip\"\n
      \ init_ip=$(bracketify $init_ip)\n  target=$(ovn-${db}ctl --timeout=5 --db=${transport}:${init_ip}:${port}
      ${ovndb_ctl_ssl_opts} \\\n            --data=bare --no-headings --columns=target
      list connection)\n  if [[ \"${target}\" != \"p${transport}:${port}${ovn_raft_conn_ip_url_suffix}\"
      ]]; then\n    echo \"Unable to check correct target ${target} \"\n    return
      1\n  fi\n  echo \"${pod} is part of cluster\"\n  return 0\n}\n# end of db_part_of_cluster\n\n#
      Checks if cluster has already been initialized.\n# If not it returns false and
      sets init_ip to CLUSTER_INITIATOR_IP\ncluster_exists() {\n  local db=${1}\n
      \ local port=${2}\n  # TODO: change to use '--request-timeout=5s', if https://github.com/kubernetes/kubernetes/issues/49343
      is fixed. \n  db_pods=$(timeout 5 kubectl get pod -n ${ovn_kubernetes_namespace}
      -o=jsonpath='{.items[*].metadata.name}' | egrep -o 'ovnkube-master-\\w+' | grep
      -v \"metrics\")\n\n  for db_pod in $db_pods; do\n    if db_part_of_cluster $db_pod
      $db $port; then\n      echo \"${db_pod} is part of current cluster with ip:
      ${init_ip}!\"\n      return 0\n    fi\n  done\n  # if we get here  there is
      no cluster, set init_ip and get out\n  init_ip=$(bracketify $CLUSTER_INITIATOR_IP)\n
      \ return 1\n}\n# end of cluster_exists()\n\n# RAFT clusters need an odd number
      of members to achieve consensus.\n# The CNO determines which members make up
      the cluster, so if this container\n# is not supposed to be part of the cluster,
      wait forever doing nothing\n# (instad of exiting and causing CrashLoopBackoffs
      for no reason).\nif [[ ! \"ssl:10.0.130.93:9641\" =~ .*\":${K8S_NODE_IP}:\".*
      ]] && [[ ! \"ssl:10.0.130.93:9641\" =~ .*\":[${K8S_NODE_IP}]:\".* ]]; then\n
      \ echo \"$(date -Iseconds) - not selected as RAFT member; sleeping...\"\n  sleep
      1500d\n  exit 0\nfi\n\nOVN_ARGS=\"--db-nb-cluster-local-port=9643 \\\n  --db-nb-cluster-local-addr=$(bracketify
      ${K8S_NODE_IP}) \\\n  --no-monitor \\\n  --db-nb-cluster-local-proto=ssl \\\n
      \ --ovn-nb-db-ssl-key=/ovn-cert/tls.key \\\n  --ovn-nb-db-ssl-cert=/ovn-cert/tls.crt
      \\\n  --ovn-nb-db-ssl-ca-cert=/ovn-ca/ca-bundle.crt\"\n\nCLUSTER_INITIATOR_IP=\"10.0.130.93\"\necho
      \"$(date -Iseconds) - starting nbdb  CLUSTER_INITIATOR_IP=${CLUSTER_INITIATOR_IP},
      K8S_NODE_IP=${K8S_NODE_IP}\"\ninitialize=\"false\"\n\nif [[ ! -e ${ovn_db_file}
      ]]; then\n  initialize=\"true\"\nfi\n\nif [[ \"${initialize}\" == \"true\" ]];
      then\n  # check to see if a cluster already exists. If it does, just join it.\n
      \ counter=0\n  cluster_found=false\n  while [ $counter -lt 5 ]; do\n    if cluster_exists
      ${db} ${db_port}; then\n      cluster_found=true\n      break\n    fi\n    sleep
      1\n    counter=$((counter+1))\n  done\n\n  if ${cluster_found}; then\n    echo
      \"Cluster already exists for DB: ${db}\"\n    # join existing cluster\n    exec
      /usr/share/ovn/scripts/ovn-ctl ${OVN_ARGS} \\\n    --db-nb-cluster-remote-port=9643
      \\\n    --db-nb-cluster-remote-addr=${init_ip} \\\n    --db-nb-cluster-remote-proto=ssl
      \\\n    --ovn-nb-log=\"-vconsole:${OVN_LOG_LEVEL} -vfile:off -vPATTERN:console:%D{%Y-%m-%dT%H:%M:%S.###Z}|%05N|%c%T|%p|%m\"
      \\\n    run_nb_ovsdb &\n\n    wait $!\n  else\n    # either we need to initialize
      a new cluster or wait for master to create it\n    if [[ \"${K8S_NODE_IP}\"
      == \"${CLUSTER_INITIATOR_IP}\" ]]; then\n      # set DB election timer at DB
      creation time if OVN supports it\n      election_timer=\n      if test -n \"$(/usr/share/ovn/scripts/ovn-ctl
      --help 2>&1 | grep \"\\--db-nb-election-timer\")\"; then\n        election_timer=\"--db-nb-election-timer=$((10*1000))\"\n
      \     fi\n\n      exec /usr/share/ovn/scripts/ovn-ctl ${OVN_ARGS} \\\n      --ovn-nb-log=\"-vconsole:${OVN_LOG_LEVEL}
      -vfile:off -vPATTERN:console:%D{%Y-%m-%dT%H:%M:%S.###Z}|%05N|%c%T|%p|%m\" \\\n
      \     ${election_timer} \\\n      run_nb_ovsdb &\n\n      wait $!\n    else\n
      \     echo \"Joining the nbdb cluster with init_ip=${init_ip}...\"\n      exec
      /usr/share/ovn/scripts/ovn-ctl ${OVN_ARGS} \\\n      --db-nb-cluster-remote-port=9643
      \\\n      --db-nb-cluster-remote-addr=${init_ip} \\\n      --db-nb-cluster-remote-proto=ssl
      \\\n      --ovn-nb-log=\"-vconsole:${OVN_LOG_LEVEL} -vfile:off -vPATTERN:console:%D{%Y-%m-%dT%H:%M:%S.###Z}|%05N|%c%T|%p|%m\"
      \\\n      run_nb_ovsdb &\n\n      wait $!\n    fi\n  fi\nelse\n  exec /usr/share/ovn/scripts/ovn-ctl
      ${OVN_ARGS} \\\n    --ovn-nb-log=\"-vconsole:${OVN_LOG_LEVEL} -vfile:off -vPATTERN:console:%D{%Y-%m-%dT%H:%M:%S.###Z}|%05N|%c%T|%p|%m\"
      \\\n    run_nb_ovsdb &\n\n    wait $!\nfi\n"
    env:
    - name: OVN_LOG_LEVEL
      value: info
    - name: OVN_NORTHD_PROBE_INTERVAL
      value: "10000"
    - name: K8S_NODE_IP
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: status.hostIP
    image: registry.build05.ci.openshift.org/ci-ln-88xnydk/stable@sha256:d554d78ce21caa55b704d4621d7a2ba806dd6321912c36d5cd8b61e9a0934d0b
    imagePullPolicy: IfNotPresent
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            set -x
            CLUSTER_INITIATOR_IP="10.0.130.93"
            rm -f /var/run/ovn/ovnnb_db.pid

            # exit early if this DB is not supposed to be part of the cluster
            if [[ ! "ssl:10.0.130.93:9641" =~ .*":${K8S_NODE_IP}:".* ]] && [[ ! "ssl:10.0.130.93:9641" =~ .*":[${K8S_NODE_IP}]:".* ]]; then
              exit 0
            fi

            # retry an operation a number of times, sleeping 2 seconds between each try
            retry() {
              local tries=${1}
              local desc=${2}
              local cmd=${3}

              local retries=0
              while ! ${cmd}; do
                (( retries += 1 ))
                if [[ "${retries}" -gt ${tries} ]]; then
                  echo "$(date -Iseconds) - ERROR - nbdb ${desc} - too many failed attempts, giving up"
                  return 1
                fi
                echo "$(date -Iseconds) - WARN - nbdb ${desc} - failed try ${retries}, retrying..."
                sleep 2
              done
              echo "$(date -Iseconds) - INFO - nbdb ${desc} - success"
              return 0
            }

            if [[ "${K8S_NODE_IP}" == "${CLUSTER_INITIATOR_IP}" ]]; then
              echo "$(date -Iseconds) - nbdb - postStart - waiting for master to be selected"

              # set the connection and inactivity probe
              if ! retry 60 "inactivity-probe" "ovn-nbctl --no-leader-only -t 5 set-connection pssl:9641 -- set connection . inactivity_probe=60000"; then
                exit 1
              fi

              # Upgrade the db if required.
              DB_SCHEMA="/usr/share/ovn/ovn-nb.ovsschema"
              DB_SERVER="unix:/var/run/ovn/ovnnb_db.sock"
              schema_name=$(ovsdb-tool schema-name $DB_SCHEMA)
              db_version=$(ovsdb-client -t 10 get-schema-version "$DB_SERVER" "$schema_name")
              target_version=$(ovsdb-tool schema-version "$DB_SCHEMA")

              if ovsdb-tool compare-versions "$db_version" == "$target_version"; then
                :
              elif ovsdb-tool compare-versions "$db_version" ">" "$target_version"; then
                  echo "Database $schema_name has newer schema version ($db_version) than our local schema ($target_version), possibly an upgrade is partially complete?"
              else
                  echo "Upgrading database $schema_name from schema version $db_version to $target_version"
                  ovsdb-client -t 30 convert "$DB_SERVER" "$DB_SCHEMA"
              fi
            fi

            # read the current northd_probe_interval from the DB
            OVN_NB_CTL="ovn-nbctl -p /ovn-cert/tls.key -c /ovn-cert/tls.crt -C /ovn-ca/ca-bundle.crt --db "ssl:10.0.130.93:9641""
            northd_probe_interval=${OVN_NORTHD_PROBE_INTERVAL:-10000}
            echo "Setting northd probe interval to ${northd_probe_interval} ms"
            retries=0
            current_probe_interval=0
            while [[ "${retries}" -lt 20 ]]; do
              current_probe_interval=$(${OVN_NB_CTL} --if-exists get NB_GLOBAL . options:northd_probe_interval)
              if [[ $? == 0 ]]; then
                current_probe_interval=$(echo ${current_probe_interval} | tr -d '\"')
                break
              else
                sleep 2
                (( retries += 1 ))
              fi
            done

            # ensure the northd_probe_interval is set to the configured value
            if [[ "${current_probe_interval}" != "${northd_probe_interval}" ]]; then
              if ! retry 20 "northd-probe" "${OVN_NB_CTL} set NB_GLOBAL . options:northd_probe_interval=${northd_probe_interval}"; then
                exit 1
              fi
            fi

            # Enable/disable IPsec

            ipsec=false

            if ! retry 20 "ipsec" "${OVN_NB_CTL} set nb_global . ipsec=${ipsec}"; then
              exit 1
            fi
      preStop:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "$(date -Iseconds) - stopping nbdb"
            /usr/share/ovn/scripts/ovn-ctl stop_nb_ovsdb
            echo "$(date -Iseconds) - nbdb stopped"
            rm -f /var/run/ovn/ovnnb_db.pid
    name: nbdb
    ports:
    - containerPort: 9641
      hostPort: 9641
      name: nb-db-port
      protocol: TCP
    - containerPort: 9643
      hostPort: 9643
      name: nb-db-raft-port
      protocol: TCP
    readinessProbe:
      exec:
        command:
        - /bin/bash
        - -c
        - |
          set -xeo pipefail

          # exit early if this DB is not supposed to be part of the cluster
          if [[ ! "ssl:10.0.130.93:9641" =~ .*":${K8S_NODE_IP}:".* ]] && [[ ! "ssl:10.0.130.93:9641" =~ .*":[${K8S_NODE_IP}]:".* ]]; then
            exit 0
          fi

          leader_status=$(/usr/bin/ovn-appctl -t /var/run/ovn/ovnnb_db.ctl --timeout=3 cluster/status OVN_Northbound  2>/dev/null | { grep "Leader: unknown" || true; })
          if [[ ! -z "${leader_status}" ]]; then
            echo "NB DB Raft leader is unknown to the cluster node."
            exit 1
          fi
          # set trim-on-compaction
          /usr/bin/ovn-appctl -t /var/run/ovn/ovnnb_db.ctl --timeout=5 ovsdb-server/memory-trim-on-compaction on 2>/dev/null
      failureThreshold: 3
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 5
    resources:
      requests:
        cpu: 10m
        memory: 300Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/openvswitch/
      name: etc-openvswitch
    - mountPath: /etc/ovn/
      name: etc-openvswitch
    - mountPath: /var/lib/openvswitch/
      name: var-lib-openvswitch
    - mountPath: /run/openvswitch/
      name: run-openvswitch
    - mountPath: /run/ovn/
      name: run-ovn
    - mountPath: /env
      name: env-overrides
    - mountPath: /ovn-cert
      name: ovn-cert
    - mountPath: /ovn-ca
      name: ovn-ca
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-vbjr8
      readOnly: true
  - command:
    - /bin/bash
    - -c
    - |
      #!/bin/bash
      set -euo pipefail
      TLS_PK=/etc/pki/tls/metrics-cert/tls.key
      TLS_CERT=/etc/pki/tls/metrics-cert/tls.crt
      # As the secret mount is optional we must wait for the files to be present.
      # The service is created in monitor.yaml and this is created in sdn.yaml.
      TS=$(date +%s)
      WARN_TS=$(( ${TS} + $(( 20 * 60)) ))
      HAS_LOGGED_INFO=0

      log_missing_certs(){
          CUR_TS=$(date +%s)
          if [[ "${CUR_TS}" -gt "WARN_TS"  ]]; then
            echo $(date -Iseconds) WARN: ovn-master-metrics-cert not mounted after 20 minutes.
          elif [[ "${HAS_LOGGED_INFO}" -eq 0 ]] ; then
            echo $(date -Iseconds) INFO: ovn-master-metrics-cert not mounted. Waiting 20 minutes.
            HAS_LOGGED_INFO=1
          fi
      }
      while [[ ! -f "${TLS_PK}" ||  ! -f "${TLS_CERT}" ]] ; do
        log_missing_certs
        sleep 5
      done

      echo $(date -Iseconds) INFO: ovn-master-metrics-certs mounted, starting kube-rbac-proxy
      exec /usr/bin/kube-rbac-proxy \
        --logtostderr \
        --secure-listen-address=:9102 \
        --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \
        --upstream=http://127.0.0.1:29102/ \
        --tls-private-key-file=${TLS_PK} \
        --tls-cert-file=${TLS_CERT}
    image: registry.build05.ci.openshift.org/ci-ln-88xnydk/stable@sha256:199a16f6e9bdfc720f6efa5cb21b207d79ef1fcda9c58e5dbef1f2d2fc09d747
    imagePullPolicy: IfNotPresent
    name: kube-rbac-proxy
    ports:
    - containerPort: 9102
      hostPort: 9102
      name: https
      protocol: TCP
    resources:
      requests:
        cpu: 10m
        memory: 20Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/pki/tls/metrics-cert
      name: ovn-master-metrics-cert
      readOnly: true
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-vbjr8
      readOnly: true
  - command:
    - /bin/bash
    - -c
    - "set -xm\nif [[ -f /env/_master ]]; then\n  set -o allexport\n  source /env/_master\n
      \ set +o allexport\nfi\n\nquit() {\n  echo \"$(date -Iseconds) - stopping sbdb\"\n
      \ /usr/share/ovn/scripts/ovn-ctl stop_sb_ovsdb\n  echo \"$(date -Iseconds) -
      sbdb stopped\"\n  rm -f /var/run/ovn/ovnsb_db.pid\n  exit 0\n}\n# end of quit\ntrap
      quit TERM INT\n\nbracketify() { case \"$1\" in *:*) echo \"[$1]\" ;; *) echo
      \"$1\" ;; esac }\n\n# initialize variables\novn_kubernetes_namespace=openshift-ovn-kubernetes\novndb_ctl_ssl_opts=\"-p
      /ovn-cert/tls.key -c /ovn-cert/tls.crt -C /ovn-ca/ca-bundle.crt\"\ntransport=\"ssl\"\novn_raft_conn_ip_url_suffix=\"\"\nif
      [[ \"${K8S_NODE_IP}\" == *\":\"* ]]; then\n  ovn_raft_conn_ip_url_suffix=\":[::]\"\nfi\ndb=\"sb\"\ndb_port=\"9642\"\novn_db_file=\"/etc/ovn/ovn${db}_db.db\"\n#
      checks if a db pod is part of a current cluster\ndb_part_of_cluster() {\n  local
      pod=${1}\n  local db=${2}\n  local port=${3}\n  echo \"Checking if ${pod} is
      part of cluster\"\n  # TODO: change to use '--request-timeout=5s', if https://github.com/kubernetes/kubernetes/issues/49343
      is fixed. \n  init_ip=$(timeout 5 kubectl get pod -n ${ovn_kubernetes_namespace}
      ${pod} -o=jsonpath='{.status.podIP}')\n  if [[ $? != 0 ]]; then\n    echo \"Unable
      to get ${pod} ip \"\n    return 1\n  fi\n  echo \"Found ${pod} ip: $init_ip\"\n
      \ init_ip=$(bracketify $init_ip)\n  target=$(ovn-${db}ctl --timeout=5 --db=${transport}:${init_ip}:${port}
      ${ovndb_ctl_ssl_opts} \\\n            --data=bare --no-headings --columns=target
      list connection)\n  if [[ \"${target}\" != \"p${transport}:${port}${ovn_raft_conn_ip_url_suffix}\"
      ]]; then\n    echo \"Unable to check correct target ${target} \"\n    return
      1\n  fi\n  echo \"${pod} is part of cluster\"\n  return 0\n}\n# end of db_part_of_cluster\n\n#
      Checks if cluster has already been initialized.\n# If not it returns false and
      sets init_ip to CLUSTER_INITIATOR_IP\ncluster_exists() {\n  local db=${1}\n
      \ local port=${2}\n  # TODO: change to use '--request-timeout=5s', if https://github.com/kubernetes/kubernetes/issues/49343
      is fixed. \n  db_pods=$(timeout 5 kubectl get pod -n ${ovn_kubernetes_namespace}
      -o=jsonpath='{.items[*].metadata.name}' | egrep -o 'ovnkube-master-\\w+' | grep
      -v \"metrics\")\n\n  for db_pod in $db_pods; do\n    if db_part_of_cluster $db_pod
      $db $port; then\n      echo \"${db_pod} is part of current cluster with ip:
      ${init_ip}!\"\n      return 0\n    fi\n  done\n  # if we get here  there is
      no cluster, set init_ip and get out\n  init_ip=$(bracketify $CLUSTER_INITIATOR_IP)\n
      \ return 1\n}\n# end of cluster_exists()\n\n# RAFT clusters need an odd number
      of members to achieve consensus.\n# The CNO determines which members make up
      the cluster, so if this container\n# is not supposed to be part of the cluster,
      wait forever doing nothing\n# (instad of exiting and causing CrashLoopBackoffs
      for no reason).\nif [[ ! \"ssl:10.0.130.93:9642\" =~ .*\":${K8S_NODE_IP}:\".*
      ]] && [[ ! \"ssl:10.0.130.93:9642\" =~ .*\":[${K8S_NODE_IP}]:\".* ]]; then\n
      \ echo \"$(date -Iseconds) - not selected as RAFT member; sleeping...\"\n  sleep
      1500d\n  exit 0\nfi\n\nOVN_ARGS=\"--db-sb-cluster-local-port=9644 \\\n  --db-sb-cluster-local-addr=$(bracketify
      ${K8S_NODE_IP}) \\\n  --no-monitor \\\n  --db-sb-cluster-local-proto=ssl \\\n
      \ --ovn-sb-db-ssl-key=/ovn-cert/tls.key \\\n  --ovn-sb-db-ssl-cert=/ovn-cert/tls.crt
      \\\n  --ovn-sb-db-ssl-ca-cert=/ovn-ca/ca-bundle.crt\"\n\nCLUSTER_INITIATOR_IP=\"10.0.130.93\"\necho
      \"$(date -Iseconds) - starting sbdb  CLUSTER_INITIATOR_IP=${CLUSTER_INITIATOR_IP}\"\ninitialize=\"false\"\n\nif
      [[ ! -e ${ovn_db_file} ]]; then\n  initialize=\"true\"\nfi\n\nif [[ \"${initialize}\"
      == \"true\" ]]; then\n  # check to see if a cluster already exists. If it does,
      just join it.\n  counter=0\n  cluster_found=false\n  while [ $counter -lt 5
      ]; do\n    if cluster_exists ${db} ${db_port}; then\n      cluster_found=true\n
      \     break\n    fi\n    sleep 1\n    counter=$((counter+1))\n  done\n\n  if
      ${cluster_found}; then\n    echo \"Cluster already exists for DB: ${db}\"\n
      \   # join existing cluster\n    exec /usr/share/ovn/scripts/ovn-ctl ${OVN_ARGS}
      \\\n    --db-sb-cluster-remote-port=9644 \\\n    --db-sb-cluster-remote-addr=${init_ip}
      \\\n    --db-sb-cluster-remote-proto=ssl \\\n    --ovn-sb-log=\"-vconsole:${OVN_LOG_LEVEL}
      -vfile:off -vPATTERN:console:%D{%Y-%m-%dT%H:%M:%S.###Z}|%05N|%c%T|%p|%m\" \\\n
      \   run_sb_ovsdb &\n\n    wait $!\n  else\n    # either we need to initialize
      a new cluster or wait for master to create it\n    if [[ \"${K8S_NODE_IP}\"
      == \"${CLUSTER_INITIATOR_IP}\" ]]; then\n      # set DB election timer at DB
      creation time if OVN supports it\n      election_timer=\n      if test -n \"$(/usr/share/ovn/scripts/ovn-ctl
      --help 2>&1 | grep \"\\--db-sb-election-timer\")\"; then\n        election_timer=\"--db-sb-election-timer=$((16*1000))\"\n
      \     fi\n\n      exec /usr/share/ovn/scripts/ovn-ctl ${OVN_ARGS} \\\n      --ovn-sb-log=\"-vconsole:${OVN_LOG_LEVEL}
      -vfile:off -vPATTERN:console:%D{%Y-%m-%dT%H:%M:%S.###Z}|%05N|%c%T|%p|%m\" \\\n
      \     ${election_timer} \\\n      run_sb_ovsdb &\n\n      wait $!\n    else\n
      \     exec /usr/share/ovn/scripts/ovn-ctl ${OVN_ARGS} \\\n      --db-sb-cluster-remote-port=9644
      \\\n      --db-sb-cluster-remote-addr=${init_ip} \\\n      --db-sb-cluster-remote-proto=ssl
      \\\n      --ovn-sb-log=\"-vconsole:${OVN_LOG_LEVEL} -vfile:off -vPATTERN:console:%D{%Y-%m-%dT%H:%M:%S.###Z}|%05N|%c%T|%p|%m\"
      \\\n      run_sb_ovsdb &\n\n      wait $!\n    fi\n  fi\nelse\n  exec /usr/share/ovn/scripts/ovn-ctl
      ${OVN_ARGS} \\\n  --ovn-sb-log=\"-vconsole:${OVN_LOG_LEVEL} -vfile:off -vPATTERN:console:%D{%Y-%m-%dT%H:%M:%S.###Z}|%05N|%c%T|%p|%m\"
      \\\n  run_sb_ovsdb &\n\n  wait $!\nfi\n"
    env:
    - name: OVN_LOG_LEVEL
      value: info
    - name: K8S_NODE_IP
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: status.hostIP
    image: registry.build05.ci.openshift.org/ci-ln-88xnydk/stable@sha256:d554d78ce21caa55b704d4621d7a2ba806dd6321912c36d5cd8b61e9a0934d0b
    imagePullPolicy: IfNotPresent
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            set -x
            CLUSTER_INITIATOR_IP="10.0.130.93"
            rm -f /var/run/ovn/ovnsb_db.pid

            # exit early if this DB is not supposed to be part of the cluster
            if [[ ! "ssl:10.0.130.93:9642" =~ .*":${K8S_NODE_IP}:".* ]] && [[ ! "ssl:10.0.130.93:9642" =~ .*":[${K8S_NODE_IP}]:".* ]]; then
              exit 0
            fi

            # retry an operation a number of times, sleeping 2 seconds between each try
            retry() {
              local tries=${1}
              local desc=${2}
              local cmd=${3}

              local retries=0
              while ! ${cmd}; do
                (( retries += 1 ))
                if [[ "${retries}" -gt ${tries} ]]; then
                  echo "$(date -Iseconds) - ERROR - nbdb ${desc} - too many failed attempts, giving up"
                  return 1
                fi
                echo "$(date -Iseconds) - WARN - nbdb ${desc} - failed try ${retries}, retrying..."
                sleep 2
              done
              echo "$(date -Iseconds) - INFO - nbdb ${desc} - success"
              return 0
            }

            if [[ "${K8S_NODE_IP}" == "${CLUSTER_INITIATOR_IP}" ]]; then
              echo "$(date -Iseconds) - sdb - postStart - waiting for master to be selected"

              # set the connection and inactivity probe
              if ! retry 60 "inactivity-probe" "ovn-sbctl --no-leader-only -t 5 set-connection pssl:9642 -- set connection . inactivity_probe=180000"; then
                exit 1
              fi

              # Upgrade the db if required.
              DB_SCHEMA="/usr/share/ovn/ovn-sb.ovsschema"
              DB_SERVER="unix:/var/run/ovn/ovnsb_db.sock"
              schema_name=$(ovsdb-tool schema-name $DB_SCHEMA)
              db_version=$(ovsdb-client -t 10 get-schema-version "$DB_SERVER" "$schema_name")
              target_version=$(ovsdb-tool schema-version "$DB_SCHEMA")

              if ovsdb-tool compare-versions "$db_version" == "$target_version"; then
                :
              elif ovsdb-tool compare-versions "$db_version" ">" "$target_version"; then
                  echo "Database $schema_name has newer schema version ($db_version) than our local schema ($target_version), possibly an upgrade is partially complete?"
              else
                  echo "Upgrading database $schema_name from schema version $db_version to $target_version"
                  ovsdb-client -t 30 convert "$DB_SERVER" "$DB_SCHEMA"
              fi
            fi

            # Kill some time while the cluster converges by checking IPsec status
            OVN_SB_CTL="ovn-sbctl -p /ovn-cert/tls.key -c /ovn-cert/tls.crt -C /ovn-ca/ca-bundle.crt --db "ssl:10.0.130.93:9642""
            if ! retry 20 "ipsec" "${OVN_SB_CTL} get sb_global . ipsec"; then
              exit 1
            fi
      preStop:
        exec:
          command:
          - /bin/bash
          - -c
          - |
            echo "$(date -Iseconds) - stopping sbdb"
            /usr/share/ovn/scripts/ovn-ctl stop_sb_ovsdb
            echo "$(date -Iseconds) - sbdb stopped"
            rm -f /var/run/ovn/ovnsb_db.pid
    name: sbdb
    ports:
    - containerPort: 9642
      hostPort: 9642
      name: sb-db-port
      protocol: TCP
    - containerPort: 9644
      hostPort: 9644
      name: sb-db-raft-port
      protocol: TCP
    readinessProbe:
      exec:
        command:
        - /bin/bash
        - -c
        - |
          set -xeo pipefail

          # exit early if this DB is not supposed to be part of the cluster
          if [[ ! "ssl:10.0.130.93:9642" =~ .*":${K8S_NODE_IP}:".* ]] && [[ ! "ssl:10.0.130.93:9642" =~ .*":[${K8S_NODE_IP}]:".* ]]; then
            exit 0
          fi

          leader_status=$(/usr/bin/ovn-appctl -t /var/run/ovn/ovnsb_db.ctl --timeout=3 cluster/status OVN_Southbound  2>/dev/null | { grep "Leader: unknown" || true; })
          if [[ ! -z "${leader_status}" ]]; then
            echo "SB DB Raft leader is unknown to the cluster node."
            exit 1
          fi
          # set trim-on-compaction
          /usr/bin/ovn-appctl -t /var/run/ovn/ovnsb_db.ctl --timeout=5 ovsdb-server/memory-trim-on-compaction on 2>/dev/null
      failureThreshold: 3
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 5
    resources:
      requests:
        cpu: 10m
        memory: 300Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/openvswitch/
      name: etc-openvswitch
    - mountPath: /etc/ovn/
      name: etc-openvswitch
    - mountPath: /var/lib/openvswitch/
      name: var-lib-openvswitch
    - mountPath: /run/openvswitch/
      name: run-openvswitch
    - mountPath: /run/ovn/
      name: run-ovn
    - mountPath: /env
      name: env-overrides
    - mountPath: /ovn-cert
      name: ovn-cert
    - mountPath: /ovn-ca
      name: ovn-ca
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-vbjr8
      readOnly: true
  - command:
    - /bin/bash
    - -c
    - |
      set -xe
      if [[ -f "/env/_master" ]]; then
        set -o allexport
        source "/env/_master"
        set +o allexport
      fi

      if [ "shared" == "shared" ]; then
        gateway_mode_flags="--gateway-mode shared --gateway-interface br-ex"
      elif [ "shared" == "local" ]; then
        gateway_mode_flags="--gateway-mode local --gateway-interface br-ex"
      else
        echo "Invalid OVN_GATEWAY_MODE: \"shared\". Must be \"local\" or \"shared\"."
        exit 1
      fi

      multi_network_enabled_flag=
      if [[ "true" == "true" ]]; then
        multi_network_enabled_flag="--enable-multi-network"
      fi

      echo "I$(date "+%m%d %H:%M:%S.%N") - ovnkube-master - start ovnkube --init-master ${K8S_NODE}"
      exec /usr/bin/ovnkube \
        --init-master "${K8S_NODE}" \
        --config-file=/run/ovnkube-config/ovnkube.conf \
        --ovn-empty-lb-events \
        --loglevel "${OVN_KUBE_LOG_LEVEL}" \
        --metrics-bind-address "127.0.0.1:29102" \
        --metrics-enable-pprof \
        --metrics-enable-config-duration \
        ${gateway_mode_flags} \
        --sb-address "ssl:10.0.130.93:9642" \
        --sb-client-privkey /ovn-cert/tls.key \
        --sb-client-cert /ovn-cert/tls.crt \
        --sb-client-cacert /ovn-ca/ca-bundle.crt \
        --sb-cert-common-name "ovn" \
        --nb-address "ssl:10.0.130.93:9641" \
        --nb-client-privkey /ovn-cert/tls.key \
        --nb-client-cert /ovn-cert/tls.crt \
        --nb-client-cacert /ovn-ca/ca-bundle.crt \
        --nb-cert-common-name "ovn" \
        --enable-multicast \
        --disable-snat-multiple-gws \
        ${multi_network_enabled_flag} \
        --acl-logging-rate-limit "20"
    env:
    - name: OVN_KUBE_LOG_LEVEL
      value: "4"
    - name: K8S_NODE
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: spec.nodeName
    image: registry.build05.ci.openshift.org/ci-ln-88xnydk/stable@sha256:d554d78ce21caa55b704d4621d7a2ba806dd6321912c36d5cd8b61e9a0934d0b
    imagePullPolicy: IfNotPresent
    name: ovnkube-master
    ports:
    - containerPort: 29102
      hostPort: 29102
      name: metrics-port
      protocol: TCP
    resources:
      requests:
        cpu: 10m
        memory: 300Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/systemd/system
      name: systemd-units
      readOnly: true
    - mountPath: /etc/openvswitch/
      name: etc-openvswitch
    - mountPath: /etc/ovn/
      name: etc-openvswitch
    - mountPath: /var/lib/openvswitch/
      name: var-lib-openvswitch
    - mountPath: /run/openvswitch/
      name: run-openvswitch
    - mountPath: /run/ovn/
      name: run-ovn
    - mountPath: /run/ovnkube-config/
      name: ovnkube-config
    - mountPath: /env
      name: env-overrides
    - mountPath: /ovn-cert
      name: ovn-cert
    - mountPath: /ovn-ca
      name: ovn-ca
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-vbjr8
      readOnly: true
  - command:
    - /bin/bash
    - -c
    - |
      set -xe
      if [[ -f "/env/_master" ]]; then
        set -o allexport
        source "/env/_master"
        set +o allexport
      fi

      echo "I$(date "+%m%d %H:%M:%S.%N") - ovn-dbchecker - start ovn-dbchecker"

      # RAFT clusters need an odd number of members to achieve consensus.
      # The CNO determines which members make up the cluster, so if this container
      # is not supposed to be part of the cluster, wait forever doing nothing
      # (instad of exiting and causing CrashLoopBackoffs for no reason).
      if [[ ! "ssl:10.0.130.93:9641" =~ .*":${K8S_NODE_IP}:".* ]] && [[ ! "ssl:10.0.130.93:9641" =~ .*":[${K8S_NODE_IP}]:".* ]]; then
        echo "$(date -Iseconds) - not selected as RAFT member; sleeping..."
        sleep 1500d
        exit 0
      fi

      exec /usr/bin/ovndbchecker \
        --config-file=/run/ovnkube-config/ovnkube.conf \
        --loglevel "${OVN_KUBE_LOG_LEVEL}" \
        --sb-address "ssl:10.0.130.93:9642" \
        --sb-client-privkey /ovn-cert/tls.key \
        --sb-client-cert /ovn-cert/tls.crt \
        --sb-client-cacert /ovn-ca/ca-bundle.crt \
        --sb-cert-common-name "ovn" \
        --sb-raft-election-timer "16" \
        --nb-address "ssl:10.0.130.93:9641" \
        --nb-client-privkey /ovn-cert/tls.key \
        --nb-client-cert /ovn-cert/tls.crt \
        --nb-client-cacert /ovn-ca/ca-bundle.crt \
        --nb-cert-common-name "ovn" \
        --nb-raft-election-timer "10"
    env:
    - name: OVN_KUBE_LOG_LEVEL
      value: "4"
    - name: K8S_NODE_IP
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: status.hostIP
    image: registry.build05.ci.openshift.org/ci-ln-88xnydk/stable@sha256:d554d78ce21caa55b704d4621d7a2ba806dd6321912c36d5cd8b61e9a0934d0b
    imagePullPolicy: IfNotPresent
    name: ovn-dbchecker
    resources:
      requests:
        cpu: 10m
        memory: 300Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/openvswitch/
      name: etc-openvswitch
    - mountPath: /etc/ovn/
      name: etc-openvswitch
    - mountPath: /var/lib/openvswitch/
      name: var-lib-openvswitch
    - mountPath: /run/openvswitch/
      name: run-openvswitch
    - mountPath: /run/ovn/
      name: run-ovn
    - mountPath: /run/ovnkube-config/
      name: ovnkube-config
    - mountPath: /env
      name: env-overrides
    - mountPath: /ovn-cert
      name: ovn-cert
    - mountPath: /ovn-ca
      name: ovn-ca
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-vbjr8
      readOnly: true
  dnsPolicy: Default
  enableServiceLinks: true
  hostNetwork: true
  nodeName: vrutkovs-sno
  nodeSelector:
    beta.kubernetes.io/os: linux
    node-role.kubernetes.io/master: ""
  preemptionPolicy: PreemptLowerPriority
  priority: 2000000000
  priorityClassName: system-cluster-critical
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: ovn-kubernetes-controller
  serviceAccountName: ovn-kubernetes-controller
  terminationGracePeriodSeconds: 30
  tolerations:
  - key: node-role.kubernetes.io/master
    operator: Exists
  - key: node.kubernetes.io/not-ready
    operator: Exists
  - key: node.kubernetes.io/unreachable
    operator: Exists
  - key: node.kubernetes.io/network-unavailable
    operator: Exists
  - effect: NoSchedule
    key: node.kubernetes.io/disk-pressure
    operator: Exists
  - effect: NoSchedule
    key: node.kubernetes.io/memory-pressure
    operator: Exists
  - effect: NoSchedule
    key: node.kubernetes.io/pid-pressure
    operator: Exists
  - effect: NoSchedule
    key: node.kubernetes.io/unschedulable
    operator: Exists
  volumes:
  - hostPath:
      path: /etc/systemd/system
      type: ""
    name: systemd-units
  - hostPath:
      path: /var/lib/ovn/etc
      type: ""
    name: etc-openvswitch
  - hostPath:
      path: /var/lib/ovn/data
      type: ""
    name: var-lib-openvswitch
  - hostPath:
      path: /var/run/openvswitch
      type: ""
    name: run-openvswitch
  - hostPath:
      path: /var/run/ovn
      type: ""
    name: run-ovn
  - configMap:
      defaultMode: 420
      name: ovnkube-config
    name: ovnkube-config
  - configMap:
      defaultMode: 420
      name: env-overrides
      optional: true
    name: env-overrides
  - configMap:
      defaultMode: 420
      name: ovn-ca
    name: ovn-ca
  - name: ovn-cert
    secret:
      defaultMode: 420
      secretName: ovn-cert
  - name: ovn-master-metrics-cert
    secret:
      defaultMode: 420
      optional: true
      secretName: ovn-master-metrics-cert
  - name: kube-api-access-vbjr8
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          expirationSeconds: 3607
          path: token
      - configMap:
          items:
          - key: ca.crt
            path: ca.crt
          name: kube-root-ca.crt
      - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
      - configMap:
          items:
          - key: service-ca.crt
            path: service-ca.crt
          name: openshift-service-ca.crt
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2023-03-09T14:20:33Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2023-03-09T14:29:19Z"
    status: "True"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2023-03-09T14:29:19Z"
    status: "True"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2023-03-09T14:20:33Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: cri-o://a2502c8c88714483030d39767b166f8a05c0de561a1ddcdc484ade081bcee9dd
    image: registry.build05.ci.openshift.org/ci-ln-88xnydk/stable@sha256:199a16f6e9bdfc720f6efa5cb21b207d79ef1fcda9c58e5dbef1f2d2fc09d747
    imageID: registry.build05.ci.openshift.org/ci-ln-88xnydk/stable@sha256:199a16f6e9bdfc720f6efa5cb21b207d79ef1fcda9c58e5dbef1f2d2fc09d747
    lastState: {}
    name: kube-rbac-proxy
    ready: true
    restartCount: 0
    started: true
    state:
      running:
        startedAt: "2023-03-09T14:21:12Z"
  - containerID: cri-o://b32b18f7d3e40201e029b8a202725d798392cb243f6f0b9e39c2b2e72f26213c
    image: registry.build05.ci.openshift.org/ci-ln-88xnydk/stable@sha256:d554d78ce21caa55b704d4621d7a2ba806dd6321912c36d5cd8b61e9a0934d0b
    imageID: registry.build05.ci.openshift.org/ci-ln-88xnydk/stable@sha256:d554d78ce21caa55b704d4621d7a2ba806dd6321912c36d5cd8b61e9a0934d0b
    lastState: {}
    name: nbdb
    ready: true
    restartCount: 0
    started: true
    state:
      running:
        startedAt: "2023-03-09T14:20:42Z"
  - containerID: cri-o://84db6fa3de69f9b52492386a3d8944f290ac365e23d0ae723f02abfb2658c285
    image: registry.build05.ci.openshift.org/ci-ln-88xnydk/stable@sha256:d554d78ce21caa55b704d4621d7a2ba806dd6321912c36d5cd8b61e9a0934d0b
    imageID: registry.build05.ci.openshift.org/ci-ln-88xnydk/stable@sha256:d554d78ce21caa55b704d4621d7a2ba806dd6321912c36d5cd8b61e9a0934d0b
    lastState: {}
    name: northd
    ready: true
    restartCount: 0
    started: true
    state:
      running:
        startedAt: "2023-03-09T14:20:41Z"
  - containerID: cri-o://8e572ecdc073f5897bda58e9fe8f1d9e113b1f2f596226445538c4eb4ca76009
    image: registry.build05.ci.openshift.org/ci-ln-88xnydk/stable@sha256:d554d78ce21caa55b704d4621d7a2ba806dd6321912c36d5cd8b61e9a0934d0b
    imageID: registry.build05.ci.openshift.org/ci-ln-88xnydk/stable@sha256:d554d78ce21caa55b704d4621d7a2ba806dd6321912c36d5cd8b61e9a0934d0b
    lastState: {}
    name: ovn-dbchecker
    ready: true
    restartCount: 0
    started: true
    state:
      running:
        startedAt: "2023-03-09T14:21:43Z"
  - containerID: cri-o://527f77d123c6a3e91257286ade8bb864cb2cba6a03c8eee789ad905f6d127663
    image: registry.build05.ci.openshift.org/ci-ln-88xnydk/stable@sha256:d554d78ce21caa55b704d4621d7a2ba806dd6321912c36d5cd8b61e9a0934d0b
    imageID: registry.build05.ci.openshift.org/ci-ln-88xnydk/stable@sha256:d554d78ce21caa55b704d4621d7a2ba806dd6321912c36d5cd8b61e9a0934d0b
    lastState: {}
    name: ovnkube-master
    ready: true
    restartCount: 0
    started: true
    state:
      running:
        startedAt: "2023-03-09T14:21:42Z"
  - containerID: cri-o://a27d8aeb7829bddebe34fc495f854ad5eb6149b832e8e11d4bdcb8f9b1a40725
    image: registry.build05.ci.openshift.org/ci-ln-88xnydk/stable@sha256:d554d78ce21caa55b704d4621d7a2ba806dd6321912c36d5cd8b61e9a0934d0b
    imageID: registry.build05.ci.openshift.org/ci-ln-88xnydk/stable@sha256:d554d78ce21caa55b704d4621d7a2ba806dd6321912c36d5cd8b61e9a0934d0b
    lastState: {}
    name: sbdb
    ready: true
    restartCount: 0
    started: true
    state:
      running:
        startedAt: "2023-03-09T14:21:12Z"
  hostIP: 10.0.130.93
  phase: Running
  podIP: 10.0.130.93
  podIPs:
  - ip: 10.0.130.93
  qosClass: Burstable
  startTime: "2023-03-09T14:20:33Z"
