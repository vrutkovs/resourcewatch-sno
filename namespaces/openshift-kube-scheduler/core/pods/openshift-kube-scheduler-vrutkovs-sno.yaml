apiVersion: v1
kind: Pod
metadata:
  annotations:
    kubectl.kubernetes.io/default-container: kube-scheduler
    kubernetes.io/config.hash: 4f8fa6dcc62d41639c51848a1f6d5c9f
    kubernetes.io/config.mirror: 4f8fa6dcc62d41639c51848a1f6d5c9f
    kubernetes.io/config.seen: "2023-03-08T12:10:04.073928444Z"
    kubernetes.io/config.source: file
    target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
  creationTimestamp: "2023-03-08T12:10:04Z"
  labels:
    app: openshift-kube-scheduler
    revision: "3"
    scheduler: "true"
  managedFields:
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:kubectl.kubernetes.io/default-container: {}
          f:kubernetes.io/config.hash: {}
          f:kubernetes.io/config.mirror: {}
          f:kubernetes.io/config.seen: {}
          f:kubernetes.io/config.source: {}
          f:target.workload.openshift.io/management: {}
        f:labels:
          .: {}
          f:app: {}
          f:revision: {}
          f:scheduler: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"7ba64a87-d15f-47ca-ae90-36dfe6a9c47e"}: {}
      f:spec:
        f:containers:
          k:{"name":"kube-scheduler"}:
            .: {}
            f:args: {}
            f:command: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:livenessProbe:
              .: {}
              f:failureThreshold: {}
              f:httpGet:
                .: {}
                f:path: {}
                f:port: {}
                f:scheme: {}
              f:initialDelaySeconds: {}
              f:periodSeconds: {}
              f:successThreshold: {}
              f:timeoutSeconds: {}
            f:name: {}
            f:ports:
              .: {}
              k:{"containerPort":10259,"protocol":"TCP"}:
                .: {}
                f:containerPort: {}
                f:hostPort: {}
                f:protocol: {}
            f:readinessProbe:
              .: {}
              f:failureThreshold: {}
              f:httpGet:
                .: {}
                f:path: {}
                f:port: {}
                f:scheme: {}
              f:initialDelaySeconds: {}
              f:periodSeconds: {}
              f:successThreshold: {}
              f:timeoutSeconds: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/etc/kubernetes/static-pod-certs"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/kubernetes/static-pod-resources"}:
                .: {}
                f:mountPath: {}
                f:name: {}
          k:{"name":"kube-scheduler-cert-syncer"}:
            .: {}
            f:args: {}
            f:command: {}
            f:env:
              .: {}
              k:{"name":"POD_NAME"}:
                .: {}
                f:name: {}
                f:valueFrom:
                  .: {}
                  f:fieldRef: {}
              k:{"name":"POD_NAMESPACE"}:
                .: {}
                f:name: {}
                f:valueFrom:
                  .: {}
                  f:fieldRef: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/etc/kubernetes/static-pod-certs"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/kubernetes/static-pod-resources"}:
                .: {}
                f:mountPath: {}
                f:name: {}
          k:{"name":"kube-scheduler-recovery-controller"}:
            .: {}
            f:args: {}
            f:command: {}
            f:env:
              .: {}
              k:{"name":"POD_NAMESPACE"}:
                .: {}
                f:name: {}
                f:valueFrom:
                  .: {}
                  f:fieldRef: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/etc/kubernetes/static-pod-certs"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/kubernetes/static-pod-resources"}:
                .: {}
                f:mountPath: {}
                f:name: {}
        f:dnsPolicy: {}
        f:enableServiceLinks: {}
        f:hostNetwork: {}
        f:initContainers:
          .: {}
          k:{"name":"wait-for-host-port"}:
            .: {}
            f:args: {}
            f:command: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
        f:nodeName: {}
        f:priorityClassName: {}
        f:restartPolicy: {}
        f:schedulerName: {}
        f:securityContext: {}
        f:terminationGracePeriodSeconds: {}
        f:tolerations: {}
        f:volumes:
          .: {}
          k:{"name":"cert-dir"}:
            .: {}
            f:hostPath:
              .: {}
              f:path: {}
              f:type: {}
            f:name: {}
          k:{"name":"resource-dir"}:
            .: {}
            f:hostPath:
              .: {}
              f:path: {}
              f:type: {}
            f:name: {}
    manager: kubelet
    operation: Update
    time: "2023-03-08T12:10:04Z"
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        f:conditions:
          .: {}
          k:{"type":"ContainersReady"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:message: {}
            f:reason: {}
            f:status: {}
            f:type: {}
          k:{"type":"Initialized"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"PodScheduled"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Ready"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:message: {}
            f:reason: {}
            f:status: {}
            f:type: {}
        f:containerStatuses: {}
        f:hostIP: {}
        f:initContainerStatuses: {}
        f:phase: {}
        f:podIP: {}
        f:podIPs:
          .: {}
          k:{"ip":"10.0.130.68"}:
            .: {}
            f:ip: {}
        f:startTime: {}
    manager: kubelet
    operation: Update
    subresource: status
    time: "2023-03-08T12:15:16Z"
  name: openshift-kube-scheduler-vrutkovs-sno
  namespace: openshift-kube-scheduler
  ownerReferences:
  - apiVersion: v1
    controller: true
    kind: Node
    name: vrutkovs-sno
    uid: 7ba64a87-d15f-47ca-ae90-36dfe6a9c47e
  resourceVersion: "6847"
  uid: 9776738e-c11b-491b-b4ef-accda042f50b
spec:
  containers:
  - args:
    - --config=/etc/kubernetes/static-pod-resources/configmaps/config/config.yaml
    - --cert-dir=/var/run/kubernetes
    - --authentication-kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/scheduler-kubeconfig/kubeconfig
    - --authorization-kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/scheduler-kubeconfig/kubeconfig
    - --feature-gates=APIPriorityAndFairness=true,DownwardAPIHugePages=true,OpenShiftPodSecurityAdmission=true,RetroactiveDefaultStorageClass=false,RotateKubeletServerCertificate=true
    - -v=2
    - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
    - --tls-min-version=VersionTLS12
    command:
    - hyperkube
    - kube-scheduler
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f88cd82b162343cd0e3455c1d39d0b2835e6a0e2ba99e640c12df2661d5595fd
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 3
      httpGet:
        path: healthz
        port: 10259
        scheme: HTTPS
      initialDelaySeconds: 45
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 1
    name: kube-scheduler
    ports:
    - containerPort: 10259
      hostPort: 10259
      protocol: TCP
    readinessProbe:
      failureThreshold: 3
      httpGet:
        path: healthz
        port: 10259
        scheme: HTTPS
      initialDelaySeconds: 45
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 1
    resources:
      requests:
        cpu: 15m
        memory: 50Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/kubernetes/static-pod-resources
      name: resource-dir
    - mountPath: /etc/kubernetes/static-pod-certs
      name: cert-dir
  - args:
    - --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-scheduler-cert-syncer-kubeconfig/kubeconfig
    - --namespace=$(POD_NAMESPACE)
    - --destination-dir=/etc/kubernetes/static-pod-certs
    command:
    - cluster-kube-scheduler-operator
    - cert-syncer
    env:
    - name: POD_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.namespace
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a26a8cedffe6ad1a77158ba9d87ad2b90e8076f7e6661201f6e8d838c1b8c2b
    imagePullPolicy: IfNotPresent
    name: kube-scheduler-cert-syncer
    resources:
      requests:
        cpu: 5m
        memory: 50Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/kubernetes/static-pod-resources
      name: resource-dir
    - mountPath: /etc/kubernetes/static-pod-certs
      name: cert-dir
  - args:
    - |
      timeout 3m /bin/bash -exuo pipefail -c 'while [ -n "$(ss -Htanop \( sport = 11443 \))" ]; do sleep 1; done'

      exec cluster-kube-scheduler-operator cert-recovery-controller --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-scheduler-cert-syncer-kubeconfig/kubeconfig  --namespace=${POD_NAMESPACE} --listen=0.0.0.0:11443 -v=2
    command:
    - /bin/bash
    - -euxo
    - pipefail
    - -c
    env:
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.namespace
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a26a8cedffe6ad1a77158ba9d87ad2b90e8076f7e6661201f6e8d838c1b8c2b
    imagePullPolicy: IfNotPresent
    name: kube-scheduler-recovery-controller
    resources:
      requests:
        cpu: 5m
        memory: 50Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/kubernetes/static-pod-resources
      name: resource-dir
    - mountPath: /etc/kubernetes/static-pod-certs
      name: cert-dir
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  hostNetwork: true
  initContainers:
  - args:
    - |
      echo -n "Waiting for port :10259 to be released."
      while [ -n "$(ss -Htan '( sport = 10259 )')" ]; do
        echo -n "."
        sleep 1
      done
    command:
    - /usr/bin/timeout
    - "30"
    - /bin/bash
    - -c
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f88cd82b162343cd0e3455c1d39d0b2835e6a0e2ba99e640c12df2661d5595fd
    imagePullPolicy: IfNotPresent
    name: wait-for-host-port
    resources:
      requests:
        cpu: 15m
        memory: 50Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
  nodeName: vrutkovs-sno
  preemptionPolicy: PreemptLowerPriority
  priority: 2000001000
  priorityClassName: system-node-critical
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext: {}
  terminationGracePeriodSeconds: 30
  tolerations:
  - operator: Exists
  volumes:
  - hostPath:
      path: /etc/kubernetes/static-pod-resources/kube-scheduler-pod-3
      type: ""
    name: resource-dir
  - hostPath:
      path: /etc/kubernetes/static-pod-resources/kube-scheduler-certs
      type: ""
    name: cert-dir
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2023-03-08T12:10:04Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2023-03-08T12:15:16Z"
    message: 'containers with unready status: [kube-scheduler kube-scheduler-cert-syncer
      kube-scheduler-recovery-controller]'
    reason: ContainersNotReady
    status: "False"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2023-03-08T12:15:16Z"
    message: 'containers with unready status: [kube-scheduler kube-scheduler-cert-syncer
      kube-scheduler-recovery-controller]'
    reason: ContainersNotReady
    status: "False"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2023-03-08T12:10:04Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: cri-o://fcf784972cfb819d18ff3f6e40188068da4af54f9b7e34b2206365c7789eafe8
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f88cd82b162343cd0e3455c1d39d0b2835e6a0e2ba99e640c12df2661d5595fd
    imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f88cd82b162343cd0e3455c1d39d0b2835e6a0e2ba99e640c12df2661d5595fd
    lastState: {}
    name: kube-scheduler
    ready: false
    restartCount: 0
    started: false
    state:
      terminated:
        containerID: cri-o://fcf784972cfb819d18ff3f6e40188068da4af54f9b7e34b2206365c7789eafe8
        exitCode: 0
        finishedAt: "2023-03-08T12:15:16Z"
        reason: Completed
        startedAt: "2023-03-08T12:10:05Z"
  - containerID: cri-o://8c6f5e239f196020f729e09a0cf2d53605ade6470c68050e9634fc29d15edb75
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a26a8cedffe6ad1a77158ba9d87ad2b90e8076f7e6661201f6e8d838c1b8c2b
    imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a26a8cedffe6ad1a77158ba9d87ad2b90e8076f7e6661201f6e8d838c1b8c2b
    lastState: {}
    name: kube-scheduler-cert-syncer
    ready: false
    restartCount: 0
    started: false
    state:
      terminated:
        containerID: cri-o://8c6f5e239f196020f729e09a0cf2d53605ade6470c68050e9634fc29d15edb75
        exitCode: 2
        finishedAt: "2023-03-08T12:15:16Z"
        message: |
          ult.svc, openshift.default.svc.cluster.local, not localhost-recovery
          W0308 12:14:49.813171       1 reflector.go:424] k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169: failed to list *v1.ConfigMap: Get "https://localhost:6443/api/v1/namespaces/openshift-kube-scheduler/configmaps?limit=500&resourceVersion=0": x509: certificate is valid for kubernetes, kubernetes.default, kubernetes.default.svc, kubernetes.default.svc.cluster.local, openshift, openshift.default, openshift.default.svc, openshift.default.svc.cluster.local, not localhost-recovery
          E0308 12:14:49.813235       1 reflector.go:140] k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://localhost:6443/api/v1/namespaces/openshift-kube-scheduler/configmaps?limit=500&resourceVersion=0": x509: certificate is valid for kubernetes, kubernetes.default, kubernetes.default.svc, kubernetes.default.svc.cluster.local, openshift, openshift.default, openshift.default.svc, openshift.default.svc.cluster.local, not localhost-recovery
          W0308 12:15:15.835937       1 reflector.go:424] k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169: failed to list *v1.Secret: Get "https://localhost:6443/api/v1/namespaces/openshift-kube-scheduler/secrets?limit=500&resourceVersion=0": x509: certificate is valid for kubernetes, kubernetes.default, kubernetes.default.svc, kubernetes.default.svc.cluster.local, openshift, openshift.default, openshift.default.svc, openshift.default.svc.cluster.local, not localhost-recovery
          E0308 12:15:15.835962       1 reflector.go:140] k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169: Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://localhost:6443/api/v1/namespaces/openshift-kube-scheduler/secrets?limit=500&resourceVersion=0": x509: certificate is valid for kubernetes, kubernetes.default, kubernetes.default.svc, kubernetes.default.svc.cluster.local, openshift, openshift.default, openshift.default.svc, openshift.default.svc.cluster.local, not localhost-recovery
        reason: Error
        startedAt: "2023-03-08T12:10:05Z"
  - containerID: cri-o://c652f0175f48c6211a674dc9eb39dbc790191f324372cd7fc1163b20386d1a0d
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a26a8cedffe6ad1a77158ba9d87ad2b90e8076f7e6661201f6e8d838c1b8c2b
    imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a26a8cedffe6ad1a77158ba9d87ad2b90e8076f7e6661201f6e8d838c1b8c2b
    lastState: {}
    name: kube-scheduler-recovery-controller
    ready: false
    restartCount: 0
    started: false
    state:
      terminated:
        containerID: cri-o://c652f0175f48c6211a674dc9eb39dbc790191f324372cd7fc1163b20386d1a0d
        exitCode: 0
        finishedAt: "2023-03-08T12:15:16Z"
        reason: Completed
        startedAt: "2023-03-08T12:10:05Z"
  hostIP: 10.0.130.68
  initContainerStatuses:
  - containerID: cri-o://fea6dd097a174e0347a0b4885aeba8c998b25587ee4d689671dee46f0a99dc1e
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f88cd82b162343cd0e3455c1d39d0b2835e6a0e2ba99e640c12df2661d5595fd
    imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f88cd82b162343cd0e3455c1d39d0b2835e6a0e2ba99e640c12df2661d5595fd
    lastState: {}
    name: wait-for-host-port
    ready: true
    restartCount: 0
    state:
      terminated:
        containerID: cri-o://fea6dd097a174e0347a0b4885aeba8c998b25587ee4d689671dee46f0a99dc1e
        exitCode: 0
        finishedAt: "2023-03-08T12:10:04Z"
        reason: Completed
        startedAt: "2023-03-08T12:10:04Z"
  phase: Running
  podIP: 10.0.130.68
  podIPs:
  - ip: 10.0.130.68
  qosClass: Burstable
  startTime: "2023-03-08T12:10:04Z"
